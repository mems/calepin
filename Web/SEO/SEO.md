[Search engine optimization (SEO)](https://en.wikipedia.org/wiki/Search_engine_optimization) and [App store optimization (ASO)](https://en.wikipedia.org/wiki/App_store_optimization)

- [Your Guide to App Store Optimization (ASO)](https://www.sitepoint.com/your-guide-to-app-store-optimization-aso/)

Things changes over time, but [10 Things Google Wished You Knew - Search Engine People Blog | Search Engine People](http://www.searchenginepeople.com/blog/what-google-wished-you-knew.html)

See also [HTML Accessibility](../Development/HTML/HTML.md#accessibility) and [HTML Semantics](../Development/HTML/HTML.md#patterns-markup-semantics-and-snippets).

- [Category:Search engine optimization - Wikipedia](https://en.wikipedia.org/wiki/Category:Search_engine_optimization)
- [Search Appearance - Search Console Help](https://support.google.com/webmasters/topic/4589289)
- International, Mobile, Quality: [Follow our guidelines - Search Console Help](https://support.google.com/webmasters/topic/6001981)
- [Mobile SEO — Webmaster's Mobile Guide](https://developers.google.com/webmasters/mobile-sites/mobile-seo/index)
- [Google Trends](https://www.google.com/trends/)

- [SEO is Not Hard — A step-by-step SEO Tutorial for beginners that will get you ranked every single… – Startup Grind – Medium](https://medium.com/startup-grind/seo-is-not-hard-a-step-by-step-seo-tutorial-for-beginners-that-will-get-you-ranked-every-single-1b903b3ab6bb#.rbfo6cqji)
- Google could dislike you [Search Risk - How Google Almost Killed ProtonMail - ProtonMail Blog](https://protonmail.com/blog/search-risk-google/)

- [Google Analytics In Real Life - Landing Page Optimization - YouTube](https://www.youtube.com/watch?v=N5WurXNec7E)
- [Google Analytics In Real Life - Site Search - YouTube](https://www.youtube.com/watch?v=cbtf1oyNg-8)
- [Google Analytics In Real Life - Online Checkout - YouTube](https://www.youtube.com/watch?v=3Sk7cOqB9Dk)

"sitelinks" (pages entries list below search result item) are automatically generated (using an algorithm). See [Sitelinks - Search Console Help](https://support.google.com/webmasters/answer/47334?hl=en)

Note: 404 pages are often ignored. **Check your page HTTP status.**

> - Quality and depth of content: Quality content needs to have value to your audience.
> - Shares/links from related sites: If you have accounts on several networks and want Google to know they are all related to you, link them together. If you share, keep it relevant.
> - Popularity: Who and how many people share your content, are SEO variable.
> - Accurate keywords in content, meta tags, URL: Keywords is the title of your content. Be able to sum up your content with five searchable meta tags. Be accurate, interesting, and searchable.
> - Being the original source: The person who posted it first is considered the original source.
> - Ads-to-content ratio: There is a fine line to walk between giving an audience good content, while still making enough money to run your business.
> - Good UI and UX of website: If you have confusing navigation, links that lead to broken/missing pages, navigation that requires more clicks than necessary, then it means you’re not maintaining
> - Steady flow of produced content: Another part of good UX is not being flooded by ads on a page. Continually create. Google wants fresh content on top.
> — [SEO Secrets: Reverse-Engineering Google’s Algorithm](https://medium.freecodecamp.com/seo-secrets-reverse-engineering-googles-algorithm-92fad4f5a39)

Tools, audit, checklist, etc.:

- https://github.com/marcobiedermann/search-engine-optimization Checklist
- [The 2016 SEO Checklist - ClickMinded](http://www.clickminded.com/seo-checklist/)
- [Local SEO Checklist | SEO Checklist 2016](http://localseochecklist.org/)
- [SEO Crawler | Rob Hammond](https://robhammond.co/tools/seo-crawler)
- [On-page SEO Analysis | Rob Hammond](https://robhammond.co/tools/html-analysis)
- [Yellow Lab Tools](http://yellowlab.tools/) and https://github.com/gmetais/YellowLabTools
- [Varvy SEO tool and optimization guide](https://varvy.com/)
- [Search Console - Home](https://www.google.com/webmasters/tools/home)
- [WebPagetest - Website Performance and Optimization Test](http://www.webpagetest.org/)
- [WooRank.com | SEO Checker - Website Review](https://www.woorank.com/)
- [Search Console - Disavow links](https://www.google.com/webmasters/tools/disavow-links-main) see [Disavow backlinks - Search Console Help](https://support.google.com/webmasters/answer/2648487)
- [Web Page Analyzer Free Tool for SEO](http://www.seowebpageanalyzer.com/)
- [Structured Data Testing Tool](https://search.google.com/structured-data/testing-tool) see [Home - schema.org](http://schema.org/), [Official Google Webmaster Central Blog: An improved search box within the search results](https://webmasters.googleblog.com/2014/09/improved-sitelinks-search-box.html)
- [Bing - Analyseur SEO](http://www.bing.com/toolbox/seo-analyzer)
- [Structured Data Linter](http://linter.structured-data.org/)
- [The W3C Markup Validation Service](https://validator.w3.org/)
- [Structured Data Markup Helper](https://www.google.com/webmasters/markup-helper/u/0/)
- [Validator.nu](https://validator.nu/)
- https://github.com/saymedia/seosuite
- https://github.com/eyecatchup/SEOstats
- https://github.com/mattclements/SEO-Audit
- [#1 Free Web & Mobile Analytics Software](https://matomo.org/) - analytics service (previously Piwik)
- [Open Web Analytics](http://www.openwebanalytics.com/) - analytics service
- https://github.com/Kickball/awesome-selfhosted/blob/master/README.md#analytics
- http://seositecheckup.com
- http://majesticseo.com
- http://ahrefs.com
- http://nibbler.silktide.com
- http://feedthebot.com

- [SpeedCurve: Monitor front-end performance](https://speedcurve.com/)
- [Analyse de site Web, Test de Performance et Audit qualité | Dareboost](https://www.dareboost.com/fr)
- [Rigor | The Leader in Digital Performance Management](https://rigor.com/)

## Common errors

Often related to:

- duplicate content (missing rel canonical meta, 301 redirect)
- HTTP status and server issues (4xx errors, permanent redirects, broken links, temporary redirects, pages not crawled, broken internal images)
- duplicate or missing meta tags (title, descriptions, h1) or attributes (alt, hreflang, lang) attributes, duplicate content in h1 and title, short or long title element
- HTTP links for HTTPS site
- slow page (HTML) load speed, uncached or unminified resources (JS, CSS), mixed content

- [27 of the Biggest SEO Mistakes Damaging Websites in 2020](https://www.semrush.com/blog/biggest-seo-mistakes/)

## Rank factors

1. Content
	- There is a measurable correlation between the quality of content and rankings. This is demonstrated by, among others, the analysis of two new features based primarily on word co-occurrence analysis: Proof and Relevant Terms.
	- The length of content continues to increase.
	- A good internal linking structure is an important factor, and probably the most underrated SEO measure.
2. Onpage Technical SEO
	- Onpage, the keyword remains an important part of the overall concept for SEO, often represented by a balanced presence in Title, Description, Body copy, H1, H2, etc. Needless to say, that keyword stuffing should still be avoided. However, there is a definite trend towards developing keywords to topics to generate holistic content.
	- Site load speed is a veryRF Robot important performance factor.
	- Good site architecture is the beginning and end of effective SEO.
3. Backlinks
	- The quantity and especially the quality of backlinks remains important.
	- The number of keyword backlinks continues to decrease, even if the correlation increases.
	- Backlink features for Brands (Point 6 below) appear to work differently to the rest of the URLs in SERPs.
4. Social Signals
	- There were minor changes to the previous year, with Social signals correlating slightly less with good rankings than last year.
	- Average values rose slightly.
5. User Signals
	- Both the click-through rate and the time-on-site are considerably higher in better ranking sites – this may appear obvious, but average values determined over many URLs can be used as a benchmark for your own optimization.
	- The bounce rate is lower for top-ranking URLs.
6. Improved* Brand Factor
	- There seem to be special consideration for big brands.
	- The Brand Factor and its definition have been revised this year, to show the increasing complexity of its influence and quality.

1. Relevant, comprehensive content is more important than ever
	Factors associated with the quality of content on web pages are increasing in importance. Higher ranking pages tend to have more words and are better able to give searchers the information they are looking for by covering topics more comprehensively, as well as being easier to read and understand1.Since last year the average word count on pages in the top 10 search results has increased by around a quarter (rising from 975 to 1285 words), while there is evidence that high ranking pages cover topics more comprehensively touching on a variety of related topics.
2. Pay attention to user experience and user signals
	Websites which rank higher are better structured, more often responsive, have a better internal link structure and offer a user-friendly experience. “Closely relate to the content and user experience are user signals such as time on site and bounce rates because they tell Google if people find your information useful and engaging,” said Tober. “Google can measure these signals very effectively, for example by analyzing user behavior from people who use its Google Chrome web browser. So if you want your pages to rank well, you can’t get away with providing content that isn’t relevant or by providing a poor experience.”
3. Technical optimization is a basis requirement for rankings
	In addition, technical factors such as having a title tag and description in a web page’s underlying source code, and having pages that are quick to load, are standard requirements that almost all pages in the top 30 results display.
4. Decline of single keyword focus and relevance of backlinks
	The number of backlinks to a page from other pages is still a factor that is highly correlated with search ranking positions but its importance is declining.

- [Flesch–Kincaid readability tests - Wikipedia, the free encyclopedia](https://en.wikipedia.org/wiki/Flesch%E2%80%93Kincaid_readability_tests)
- [Knowledge-Base | Searchmetrics](http://www.searchmetrics.com/knowledge-base/)
- [Searchmetrics Ranking Factors Study 2015](http://www.searchmetrics.com/knowledge-base/ranking-factors/)
- [Official Google Webmaster Central Blog: Helping users easily access content on mobile](https://webmasters.googleblog.com/2016/08/helping-users-easily-access-content-on.html)

## Data type

- [Home - schema.org](http://schema.org/)
- [Introduction to Structured Data Types  |  Search  |  Google Developers](https://developers.google.com/search/docs/data-types/data-type-selector)
- [Data types supported by Data Highlighter - Search Console Help](https://support.google.com/webmasters/topic/2774098)

## Title and meta

More useful for human than search engines.

Define a meta `og:description`, if you don't want a page content bribe as snippet (works also for Facebook share)

> Title: The first blue line of any search result is the title of the webpage. Click the title to go to the site.
> URL: In green, you'll see the web address of the web page.
> Snippet: Below the URL is text that helps show how the page relates to your query. The words you search for will show in bold to make it easier for you to decide if the page has what you're looking for.
— [Google search results page - Search Help](https://support.google.com/websearch/answer/35891?hl=en#results)

- [Create good titles and snippets in Search Results - Search Console Help](https://support.google.com/webmasters/answer/35624)
- Google Search Console > Select a property / website > Search Appearance "!" icon > "Search Appearance Overview" modal

## Sitemap

Usefull for large site, or when link discovering is hard (all links couldn't be found on each pages)

Size is limited to 50,000 URLs and 50 MB

- [Increasing the size limit of Sitemaps file to address evolving webmaster needs | Webmaster Blog](https://blogs.bing.com/webmaster/November-2016/Increasing-the-size-limit-of-Sitemaps-file-to-addr)
- [Site map — Wikipedia](https://en.wikipedia.org/wiki/Site_map)
- [Sitemaps — Wikipedia](https://en.wikipedia.org/wiki/Sitemaps)
- [Learn about sitemaps - Search Console Help](https://support.google.com/webmasters/answer/156184?hl=en)
- [sitemaps.org - Home](https://www.sitemaps.org/)

## Flash and search engines

See [JavaScript and search engines](#javascript-and-search-engines)

- [Providing alternative content for SWF files | Adobe Developer Connection](http://wayback.archive.org/web/20120911162007/http://www.adobe.com/devnet/flashplayer/articles/alternative_content.html)
- [SEO | Adobe Developer Connection](http://wayback.archive.org/web/20150505144120/http://www.adobe.com/cn/devnet/seo.html)
- [Official Google Webmaster Central Blog: Improved Flash indexing](https://webmasters.googleblog.com/2008/06/improved-flash-indexing.html)
- [SWF searchability FAQ | Adobe Developer Connection](http://wayback.archive.org/web/20120920193005/http://www.adobe.com/devnet/flashplayer/articles/swf_searchability.html)

## JavaScript and search engines

**For multiple reasons (SEO, accessibility, archive, etc.), make the content your website accessible without script.**

All crawler engines can't execute JS. Even Google Bot (one of the most advanced engine) don't always execute JS (only in rendering phase, but in crawl phase).

> Even with an improved ability to crawl JavaScript, Google will prefer pure HTML content because it takes up fewer resources.

> Googlebot uses a web rendering service (WRS) that is based on Chrome 41 (M41)
– [Rendering on Google Search | Search | Google Developers](https://developers.google.com/search/docs/guides/rendering) - 2017-08-25 (Chrome 41 was released in march 2015)

> Today, we are happy to announce that Googlebot now runs the latest Chromium rendering engine (74 at the time of this post) when rendering pages for Search. Moving forward, Googlebot will regularly update its rendering engine to ensure support for latest web platform features.
– [Official Google Webmaster Central Blog: The new evergreen Googlebot](https://webmasters.googleblog.com/2019/05/the-new-evergreen-googlebot.html)

- [Fix Search-related JavaScript problems  |  Search  |  Google Developers](https://developers.google.com/search/docs/guides/fix-search-javascript)
- [Implement dynamic rendering  |  Search  |  Google Developers](https://developers.google.com/search/docs/guides/dynamic-rendering)
- [Google Renders 98% Of Pages They Crawl But It Can Take Weeks](https://www.seroundtable.com/google-render-slow-26538.html)
- [Going Beyond Google: Are Search Engines Ready for JavaScript Crawling & Indexing? - Moz](https://moz.com/blog/search-engines-ready-for-javascript-crawling)
- [Use Fetch a Google for website - Search Console Help](https://support.google.com/webmasters/answer/6066468?hl=en) - 10 fetches per days
- [JavaScript SEO Test](http://pstenstrm.se/seo/)
- [Does Google crawl and index dynamic content?](http://www.centrical.com/test/google-json-ld-and-javascript-crawling-and-indexing-test.html)
- [Does Google execute JavaScript? | Stephan Boyer](https://www.stephanboyer.com/post/122/does-google-execute-javascript)
- [An update (March 2016) on the current state & recommendations for JavaScript in Google Search](https://plus.google.com/+JohnMueller/posts/LT4fU7kFB8W)
- [JavaScript & SEO - What You Need To Know #SMXParis](https://www.slideshare.net/Badams/javascript-seo-what-you-need-to-know-smxparis) - Crawler, Indexer and Ranker
- [Can Google Properly Crawl and Index JavaScript Frameworks? A JavaScript SEO Experiment. | Elephate](https://www.elephate.com/blog/javascript-seo-experiment/)
- [What version of Chrome is Google actually using for rendering? - DeepCrawl](https://www.deepcrawl.com/blog/news/what-version-of-chrome-is-google-actually-using-for-rendering/)
- [We Tested How Googlebot Crawls Javascript And Here's What We Learned](https://searchengineland.com/tested-googlebot-crawls-javascript-heres-learned-220157)

### `<noscript>` and search engines

Some people advice to not use noscript tag, but is not. Google itself advice using it for accessibility (and progressive enhancement) purposes:

> Place the same content from the JavaScript in a `<noscript>` tag. If you use this method, ensure the contents are exactly the same as what’s contained in the JavaScript, and that this content is shown to visitors who do not have JavaScript enabled in their browser.
— [Hidden text and links - Webmaster Tools Help](https://support.google.com/webmasters/answer/66353)

But it's recommended to use this tag for render HTML without JS especially for resources lazyloading (`img`, `video` and `audio`), but try to avoid it (especially for links) by rendrer directly in document and use unobtrusive JavaScript handle/replace it.

Note: content inside noscript tag that match a specific search will not be hightlighted in Google Search results. Because it doesn't be included in the link description, aka [snippet](https://support.google.com/websearch/answer/35891?hl=en#results).

What happend, if the script execution fail?

> À moins que javascript ne soit désactivé par le navigateur, l'image n'est pas chargée naturellement et donc peut ne jamais apparaître en cas de plantage ;
— http://dascritch.net/post/2014/06/12/Finesse-en-img#methode_noscript

- [Use of <noscript> to replace image containing text - Google Product Forums](https://productforums.google.com/forum/#!topic/webmasters/YLIQcabBrjA)
- [seo - Images within noscript - Webmasters Stack Exchange](http://webmasters.stackexchange.com/questions/38398/images-within-noscript)
- [SEO & noscript - Does Google index links in a NOSCRIPT tag?](http://www.nickpower.com/google-index-links-noscript-tag/)
- https://stackoverflow.com/questions/18245019/is-content-loaded-styled-parsed-in-the-noscript-tag-even-when-javascript-is-en
- http://www.searchenginepeople.com/blog/what-google-wished-you-knew.html
- http://searchengineland.com/google-io-new-advances-in-the-searchability-of-javascript-and-flash-but-is-it-enough-19881

## Hidden text

See [hide graphicaly a text](CSS#hide-graphicaly-a-text)

## Nofollow

- [nofollow - Wikipedia](https://en.wikipedia.org/wiki/Nofollow)
- [What About Nofollow Links?](http://www.webpagemistakes.ca/nofollow/)
- [Use rel="nofollow" for specific link - Search Console Help](https://support.google.com/webmasters/answer/96569)

## URLs

See [URI/URL](#uriurl) and [Links and alternate](#links-and-alternate)

Don't have a real impact: [15 SEO Best Practices for Structuring URLs - Moz](http://moz.com/blog/15-seo-best-practices-for-structuring-urls)

### URL Fragments

- [Frequently Asked Questions - Webmasters — Google Developers](https://developers.google.com/webmasters/ajax-crawling/docs/faq)
- [Full Specification - Webmasters — Google Developers](https://developers.google.com/webmasters/ajax-crawling/docs/specification)
- [Guide to AJAX crawling for webmasters and developers - Webmaster Tools Help](https://support.google.com/webmasters/answer/174992?hl=en)

## Crawler

- [Robots meta tag and X-Robots-Tag HTTP header specifications  |  Webmasters  |  Google Developers](https://developers.google.com/webmasters/control-crawl-index/docs/robots_meta_tag)

## `robots.txt`

```
 www.robotstxt.org/

 Allow crawling of all content
User-agent: *
Disallow:
```

Redirect `/robots.txt` to `/.well-known/robots.txt` is supported (not recommended), but with only 301 status code

- [google search console - Can Googlebot handle robots.txt with a 302 redirect? - Webmasters Stack Exchange](https://webmasters.stackexchange.com/questions/55324/can-googlebot-handle-robots-txt-with-a-302-redirect)
- [seo - Redirecting robots.txt when moving to a new domain - Webmasters Stack Exchange](https://webmasters.stackexchange.com/questions/106943/redirecting-robots-txt-when-moving-to-a-new-domain)
- [redirect - Google robots.txt for http site after redirection to https - Stack Overflow](https://stackoverflow.com/questions/47162841/google-robots-txt-for-http-site-after-redirection-to-https)
- [Test your robots.txt with the robots.txt Tester - Search Console Help](https://support.google.com/webmasters/answer/6062598?hl=en)
- [Planning on moving to HTTPS? Here are 13 FAQs! What's missing? Let me know in...](https://web.archive.org/web/20190130051831/https://plus.google.com/+JohnMueller/posts/PY1xCWbeDVC)
- [Create a robots.txt file - Search Console Help](https://support.google.com/webmasters/answer/6062596?hl=en)
- [web crawlers - Can robots.txt be in a server's sub-directory? - Webmasters Stack Exchange](https://webmasters.stackexchange.com/questions/89395/can-robots-txt-be-in-a-servers-sub-directory/125858#125858)

**Don't block web crawler for public content**:

```
 Don't do it!
User-agent: *
Disallow: /
```

But:

```
User-agent: *
Crawl-delay: 3600
```

Or

```
User-agent: *
Disallow: /user/private_page
```

To exclude folder but not sub part (files or directory) (Only with non standard `Allow` directive):

```
 Allow first then disallow
User-agent: *
Allow: /folder/archive/
Allow: /folder/lsic/
Disallow: /folder/
```

- Si une URL a déjà été indexée par Google, alors la bloquer dans le robots.txt ne changera rien : en tout cas l'URL restera indexée. En effet, Google n'ayant plus l'autorisation de crawler la page, celle-ci ne sera plus crawlée et restera dans l'index telle quelle. Pour désindexer une URL, il faut autoriser son crawl et utiliser une balise meta robots noindex ou un entête HTTP `X-Robots-Tag: noindex` (ou bien, exception, aller faire une demande de suppression d'URL dans Google Webmaster Tools).
- Ne bloquez pas le crawl des URL qui se font rediriger, sinon les moteurs ne pourront pas se rendre compte de cette redirection
- La taille maximale d'un fichier robots.txt est de 500Kb soit "seulement" 62,5Ko (ce qui dépasse sera ignoré par Google)
- le fichier robots.txt peut se retrouver lui-même indexé dans Google. Pour le désindexer, vous devez soit utiliser `X-Robots-Tag` soit interdire le crawl du fichier puis le faire supprimer de l'index dans Google Search Console.
- La directive `Crawl-delay` est gérée par Bing mais ignorée par Google (pour ce dernier, il faut configurer ce paramétrage dans Google Search Console).
- La directive `Allow` n'est pas standard, mais Google la gère
- il doit y avoir un fichier `robots.txt` pour chaque sous-domaine et pour chaque protocole (HTTP et HTTPS)
- Google accepte le fichier `robots.txt` sur le protocole FTP
- Seules 4 directives sont prises en compte par Google (la casse est ignorée pour ces directives) : `user-agent`, `disallow`, `allow`, `sitemap`

- [Robots.txt - Archiveteam](http://www.archiveteam.org/index.php?title=Robots.txt)
- [Help:Using the Wayback Machine - Wikipedia, the free encyclopedia](https://en.wikipedia.org/wiki/Help:Using_the_Wayback_Machine#Limitations)
- [Robots.txt Specifications  |  Webmasters  |  Google Developers](https://developers.google.com/webmasters/control-crawl-index/docs/robots_txt?hl=en)
- [Robots exclusion standard - Wikipedia, the free encyclopedia](https://en.wikipedia.org/wiki/Robots_exclusion_standard)
- [The Web Robots Pages](http://www.robotstxt.org/orig.html)
- https://en.wikipedia.org/robots.txt
- [seo - How to configure robots.txt file to block all but 2 directories - Stack Overflow](https://stackoverflow.com/questions/6460895/how-to-configure-robots-txt-file-to-block-all-but-2-directories)

## Mobile and search engines

If redirect base on User-Agent header, use:

```http
Vary: User-Agent
```

- [Separate URLs  |  Mobile Friendly Websites  |  Google Developers](https://developers.google.com/webmasters/mobile-sites/mobile-seo/separate-urls)

What about Google with websites desktop + mobile / desktop + AMP / desktop + mobile + AMP: [Comment Google indexe le mobile-first du site sans version mobile mais avec AMP ? - Arobasenet.com](http://www.arobasenet.com/2016/11/google-amp-mobile-first-3498.html)

## Print and search engines

- [Tracking Printed Pages (or How to Validate Assumptions) - Web Standards Sherpa](http://webstandardssherpa.com/reviews/tracking-printed-pages/)
