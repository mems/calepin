Aka gfx

## Resources

![UV Coordinates](UV%20coordinates%20-%20alternativaplatform.gif)

- [Category:Computer graphics — Wikipedia](https://en.wikipedia.org/wiki/Category:Computer_graphics)
- [How Graphic Card Work - ExtremeTech](https://www.extremetech.com/gaming/269335-how-graphics-cards-work)
- [bookmarks related to game development and realtime graphics programming](https://github.com/mattdesl/graphics-resources)
- [A list of Game Development resources to make magic happen](https://github.com/ellisonleao/magictools)
- [Scratchapixel](http://www.scratchapixel.com/)
- [AlteredQualia](http://alteredqualia.com/) - WebGL demos, algorithms (see corresponding folder of backup demos)
- [Fixing Texture Seams With Linear Least-Squares // A Random Walk Through Geek-Space](http://www.sebastiansylvan.com/post/LeastSquaresTextureSeams/) - reduce triangle effect of objects
- [Essential Math for Games Programmers](http://www.essentialmath.com/tutorial.htm)
- [Humus - Articles](http://www.humus.name/index.php?page=Articles) - Populating A Massive Game World, Practical Clustered Shading, Graphics Gems for Games, Creating Vast Game Worlds
- [Sony Pictures Imageworks - Library - Award-Winning Visual Effects and Character Animation](http://library.imageworks.com/)
- [Toxiclibsjs is a library for computational design tasks with JavaScript](https://github.com/hapticdata/toxiclibsjs) - Port of [toxiclibs](http://toxiclibs.org/)
- [Les meilleurs cours et tutoriels 2D/3D/Jeux](https://jeux.developpez.com/tutoriels/) and [Les FAQs 2D / 3D / jeux](https://jeux.developpez.com/faq/)
- [Bouba/kiki effect — Wikipedia](https://en.wikipedia.org/wiki/Bouba/kiki_effect)

GPU/3D rendering:

- [Advances in Real-Time Rendering in 3D Graphics and Games - SIGGRAPH 2012](http://advances.realtimerendering.com/s2012/index.html) and [Graphics Gems for Games - Findings from Avalanche Studios - Persson_GraphicsGemsForGames.pdf](http://www.humus.name/Articles/Persson_GraphicsGemsForGames.pdf)
- [Beyond3D](https://www.beyond3d.com/) - Portal with articles and resources about 3D graphics
- [OpenGL tutorial](http://www.opengl-tutorial.org/) - tutorials for OpenGL 3.3 and later. See https://github.com/opengl-tutorials/ogl
- [The lost art of 3D rendering without shaders](http://machinethink.net/blog/3d-rendering-without-shaders/) - How render 3D geometry
- [Graphics Programming Projects](http://graphicscodex.com/projects/projects/) - learn 3D computational graphics
- [GPU Gems 3 - Foreword](http://http.developer.nvidia.com/GPUGems3/gpugems3_pref01.html)
- [Amit’s Game Programming Information](http://www-cs-students.stanford.edu/~amitp/gameprog.html) - topics about game programming
- [Gamasutra - Features: Programming](http://www.gamasutra.com/features/programming/)
- [Articles - Articles - GameDev.net](https://www.gamedev.net/resources)
- [Learn OpenGL, extensive tutorial resource for learning Modern OpenGL](https://learnopengl.com/) - see https://github.com/JoeyDeVries/LearnOpenGL and https://learnopengl.com/book/offline%20learnopengl.pdf support also `https://learnopengl.com/?_escaped_fragment_=${hashWithoutEsclamationPoint}`
- [80 level is the best source of valuable information about the gaming industry and its recent trends.](https://80.lv/)
- [RenderDoc is a stand-alone graphics debugging tool](https://github.com/baldurk/renderdoc) - Debug tool for OpenGL, Vulkan, D3D
- [The Little Grasshopper](http://prideout.net/blog/)
- [Scratchapixel](http://www.scratchapixel.com/)
- [How does a GPU shader core work?](http://aras-p.info/texts/files/2018Academy%20-%20GPU.pdf)

Old films techniques for special effects [How some cool silent film effects were done - Album on Imgur](http://imgur.com/gallery/wUAcl)

### 3D models

See [Sample files](Sample files)

- [Sketchfab - Your 3D content online and in VR.](https://sketchfab.com/)
- [Models | 3D Resources](https://nasa3d.arc.nasa.gov/models)

### 3D tools

- [Open Asset Import Library](http://www.assimp.org/) - aka Assimp
- [gCAD3D.org](http://www.gcad3d.org/)
- [3D tools on Linux - viewers and converters - Introduction (and menu)](http://www.subdude-site.com/WebPages_Local/RefInfo/Computer/Linux/LinuxGuidesByBlaze/apps3Dtools/3D_viewers-converters/3DviewersANDconverters_intro.htm)
- [meshconv 3D model converter, convert to and from VRML, DXF, OBJ, OFF, PLY, and STL](https://www.patrickmin.com/meshconv/)
- [FreeCAD/FreeCAD: This is the official source code of FreeCAD, a free and opensource multiplatform 3D parametric modeler](https://github.com/FreeCAD/FreeCAD)
- [BRL-CAD: Open Source Solid Modeling](http://brlcad.org/)

### Demos

- [sketch of three.js](http://ykob.github.io/sketch-threejs/) - Demos by Yoichi Kobayashi. See [sketch-threejs](https://github.com/ykob/sketch-threejs). Particles, shaders
- [Sketch 023](https://mrdoob.neocities.org/023/) - Demo by MrDoob. Shader
- [Mr.doob | Three.js Sketches](http://mrdoob.com/)
- Deferred - PBR Demos by mebiusbox - see https://github.com/mebiusbox/mebiusbox.github.com/tree/master/contents/threejs
	- [Deferred (PBR + Area Light rect)](http://mebiusbox.github.io/contents/threejs/deferred_pbr_rect_area_light.html)
	- [Deferred](http://mebiusbox.github.io/contents/threejs/deferred.html)
	- [Deferred (PBR)](http://mebiusbox.github.io/contents/threejs/deferred_pbr.html)
	- [Deferred (PBR + Area Light)](http://mebiusbox.github.io/contents/threejs/deferred_pbr_area_light.html)
	- [Deferred (PBR)](http://mebiusbox.github.io/contents/threejs/deferred_pbr_check.html)
	- [Flight Demo](http://mebiusbox.github.io/contents/threejs/flight.html) - Playable plane progress in clouds
	- [Soft Particle](http://mebiusbox.github.io/contents/threejs/softparticle.html)
- [Bling: Material Test](http://www.dasprinzip.com/bitsandpieces/redplant/bling/viewer/view.html) - Diamond and gemstone
- [Digital Emily](http://alteredqualia.com/xg/examples/emily.html) - 3D portrait
- [xg - skylon spacecraft](http://alteredqualia.com/xg/examples/skylon.html) - with thrust effect
- [metal cube │ sketch of three.js](http://ykob.github.io/sketch-threejs/sketch/metal_cube.html) - Sketch-threejs by Yoichi Kobayashi. See https://github.com/ykob/sketch-threejs/
- [Some grass experiment](https://www.interascope.com/experiments/grass/) - Grass with wind effect. WebGL. Can be use for trees. Use simple meshes (triangles)

## Tips

- [Inigo Quilez :: fractals, computer graphics, mathematics, demoscene and more](http://www.iquilezles.org/www/articles/cputiles/cputiles.htm) - tile rendering (render blocks)
- [Inigo Quilez :: fractals, computer graphics, mathematics, demoscene and more](http://www.iquilezles.org/www/articles/noacos/noacos.htm) - avoiding trigonometry
- [Inigo Quilez :: fractals, computer graphics, mathematics, demoscene and more](http://www.iquilezles.org/www/articles/quaternions/quaternions.htm) - thinking with quaternions
- [GDC Vault - Technical Artist Bootcamp: The VFX of Diablo](https://www.gdcvault.com/play/1017660/Technical-Artist-Bootcamp-The-VFX)
	![GDC Vault - Technical Artist Bootcamp - The VFX of Diablo - Video](GDC Vault - Technical Artist Bootcamp - The VFX of Diablo.mp4)

	- GDC 2013
	- Session Name: Technical Artist Bootcamp: The VFX of Diablo
	- Speaker(s): Julian Love
	- Company Name(s): Blizzard Entertainment
	- Overview: Technical art is evolving rapidly. In many studios TAs play key roles in developing efficient tools pipelines, and ensuring art content is visually striking and optimized for performance. TAs bridge content and engineering, helping make both more successful. However, many studios have still not fully embraced the TA role. Their TAs are smart and eager to make an impact, but are not sure how to best prove their value, and be given key roles in development. A group of experienced, respected technical artists from across the industry would like to invite you to sit with them for a day and learn how to be a more effective TA. Speakers will focus on the tools and skills TAs can use to demonstrate their value, and further integrate technical art into their studios' pipelines and cultures. Find the worst development problems at your studio and show them what an TA can do!

	- 00:00:00: Welcome
	- 00:01:02: VFX Pillars
	- 00:02:45: Communicate Gameplay
	- 00:04:46: Designer's Vision of Ballista
	- 00:06:22: Game Play First
	- 00:07:48: Make it Relatable
	- 00:12:16: Concepts with Precedence
	- 00:16:04: Push Visually Borne Concepts
	- 00:19:38: Dont' Ruin The Experience
	- 00:22:50: Make Lasting Impressions
	- 00:24:51: (TEXI×TEX2×2) - Used To Create Dynamic Alpha Shapes
	- 00:29:19: (TEXI×TEX2×2) - And Evolving Color
	- 00:34:06: Recap
	- 00:35:29: Questions
	- 00:47:24: Thank You
- [GAT #65: Stylized VFX in RIME - YouTube](https://www.youtube.com/watch?v=fwKQyDZ4ark) - ![GAT #65: Stylized VFX in RIME](GAT%20%2365_%20Stylized%20VFX%20in%20RIME%20%281080p_30fps_H264-128kbit_AAC%29.mp4)


## Interaction

See also [draw & paint](#Draw & paint)

- [Spatial Keyframing for Performance-driven Animation](http://www-ui.is.s.u-tokyo.ac.jp/~takeo/research/squirrel/index.html)
- [My Research Theme](http://www-ui.is.s.u-tokyo.ac.jp/~takeo/research/cloth/index.html) - Clothing Manipulation
- [Simple Applet](http://www-ui.is.s.u-tokyo.ac.jp/~takeo/research/rigid/curve/index.html) - As-Rigid-As-Possible Curve Editing
- [As-Rigid-As-Possible Shape Manipulation](http://www-ui.is.s.u-tokyo.ac.jp/~takeo/research/rigid/index.html)
- [layer | PROJECTS](http://www.jst.go.jp/erato/igarashi/en/projects/layer/) - Apparent Layer Operations for the Manipulation of Deformable Objects See https://www.youtube.com/watch?v=9qyUjYG_khg
- [Bubble Clusters: An Interface for Manipulating Spatial Aggregation of Graphical Objects](http://www-ui.is.s.u-tokyo.ac.jp/~takeo/research/bubble/index.html)

## Draw & paint

See also [interaction](#Interaction)

Aka pen, pencil, paintbrush, brush effects

- [Fluid Paint](http://david.li/paint/) - see [Fluid Paint](https://github.com/dli/paint)
- https://github.com/pfnet/PaintsChainer - line drawing colorization using Neural network. See [PaintsChainer - A Neural network that automatically colors in line art](http://www.creativeai.net/posts/XBjgPDuH9K8Zq6gpi/paintschainer-a-neural-network-that-automatically-colors-in)

Draw 3D model from 2D sketch:

- [Takeo Igarashi](http://www-ui.is.s.u-tokyo.ac.jp/~takeo/teddy/teddy.htm) - Teddy: A Sketching Interface for 3D Freeform Design
- [Takeo Igarashi](http://www-ui.is.s.u-tokyo.ac.jp/~takeo/java/smoothteddy/index.html) - SmoothTeddy: Quick 3D Modeling and Painting
- [Takeo Igarashi](http://www-ui.is.s.u-tokyo.ac.jp/~takeo/chateau/chateau.htm) - Chateau : A Suggestive Interface for 3D Drawing
- [Smooth Meshes for Sketch-based Freeform Modeling](http://wayback.archive.org/web/20160616201745/http://www-ui.is.s.u-tokyo.ac.jp/~takeo/papers/i3dg2003.pdf)
- [Adaptive Unwrapping for Interactive Texture Painting](http://wayback.archive.org/web/20160616203050/http://www-ui.is.s.u-tokyo.ac.jp/%7Etakeo/papers/i3dg2001.pdf) - A Sketching Interface for 3D Freeform Design
- [Plushie:An Interactive Design System for Plush Toys](http://www.geocities.jp/igarashi_lab/plushie/index-e.html)
- [Quasimondo - Mario Klingemann's Flash Blog: Flash BitmapExporter: Compress and Save Images](http://www.quasimondo.com/archives/000572.php) - draw lines (three constants r1, r2 and r3 are called f1, f2 and f3)

## Sketch rendering

- [Implementing a "sketch" style of rendering in WebGL — Floored](http://wayback.archive.org/web/20141224123751/http://www.floored.com/blog/2014/sketch-rendering)

## 3D scan

- [Agisoft PhotoScan](http://www.agisoft.com/) - processing of digital images and generates 3D spatial data

## Vector

See also [Rendering text](#Rendering text), [Bezier](Bezier)

![Vertexes To Vector](Vector/Vertexes%20to%20vector.jpg)

- [Implementations of HTML5 Canvas](https://github.com/w3canvas)
- [Random-Access Rendering of General Vector Graphics. - ravg.pdf](http://hhoppe.com/ravg.pdf)
- [Mesh Transforms - Bartosz Ciechanowski](http://ciechanowski.me/blog/2014/05/14/mesh-transforms/)
- [Paper.js](https://github.com/paperjs/paper.js) - Vector Graphics Scripting – Scriptographer ported to JavaScript
- [veltman/flubber: Tools for smoother shape animations.](https://github.com/veltman/flubber) - shape transition

### Vectorization

Transform bitmap to vectors

- [Upload Image To Trace - Vector Magic](http://vectormagic.com/online/upload)
- [Depixelizing Pixel Art - pixel.pdf](https://johanneskopf.de/publications/pixelart/paper/pixel.pdf) [Depixelizing Pixel Art](Depixelizing Pixel Art.pdf)
- [nitoyon/PotrAs - Spark project](http://www.libspark.org/wiki/nitoyon/PotrAs) - Generates vector graphics from a b/w image. See http://www.libspark.org/svn/as3/PotrAs/

## Lighting

For 2D, 3D engine might be better for performance

For [bloom](https://learnopengl.com/#!Advanced-Lighting/Bloom), see [Blur](Blur).

- [Inigo Quilez :: fractals, computer graphics, mathematics, demoscene and more](http://www.iquilezles.org/www/articles/simplegi/simplegi.htm) - simple global illumination
- [Dynamic 2D Character Lighting | p1xelcoder](http://www.p1xelcoder.com/2013/12/14/dynamic-2d-character-lighting/)
- [Circular Harmonics](http://blackpawn.com/texts/ch/) - Spherical harmonics can be used in 3d to project lighting environments
- [3D lighting and normal mapping](https://github.com/mattdesl/lwjgl-basics/wiki/ShaderLesson6) - see also https://github.com/mattdesl/kami-demos (normals and normals-pixel)
- [InFictitious: 2.5D XNA RPG Engine - Some Technical Details](https://infictitious.blogspot.fr/2012/09/25d-xna-rpg-engine-some-technical.html) - about 2.5D lighting. See also [XNA RPG 2.5D Game Engine - Updated WIP - YouTube](https://www.youtube.com/watch?v=-Q6ISVaM5Ww) and [XNA RPG 2.5D Game Engine - Weather - YouTube](https://www.youtube.com/watch?v=vtYvNEmmHXE)
- [(1 new) \[GLSL\] Using Normal Maps to Illuminate a 2D Texture (LibGDX) - Java-Gaming.org](http://www.java-gaming.org/topics/glsl-using-normal-maps-to-illuminate-a-2d-texture-libgdx/27516/view.html)
- [Sprite Lamp](http://www.spritelamp.com/) - about dynamic lighting for 2D art (using diffuse map)
- [Area Lights](http://marcinignac.com/experiments/area-light-box/demo/) - see https://twitter.com/marcinignac/status/730053584704909312
- [//game dev log of martins upitis: //status update 04 & RGP day 8](http://devlog-martinsh.blogspot.fr/2012/10/status-update-04-rgp-day-8.html) - lens flare
- [Inigo Quilez :: fractals, computer graphics, mathematics, demoscene and more](http://www.iquilezles.org/www/articles/outdoorslighting/outdoorslighting.htm) - outdoors lighting
- [Inigo Quilez :: fractals, computer graphics, mathematics, demoscene and more](http://www.iquilezles.org/www/articles/derivative/derivative.htm) - directional derivative

Create normal map

- [Normal Map Photography](http://www.zarria.net/nrmphoto/nrmphoto.html) - Normal map + displacement map from photos

### Volumetric light

Aka Eclipse, start/sun and planets,  splotlight, godrays

- [(WebGL) Volumetric Light Approximation in Three.js - Blog - (BKcore) Thibaut Despoulain](http://bkcore.com/blog/3d/webgl-three-js-volumetric-light-godrays.html) - see `Godrays` shader https://github.com/BKcore/Three.js-extensions, https://github.com/BKcore/Three.js-experiments-pool
- [Volumetric Light Scattering in three.js](http://codepen.io/abberg/details/pbWkjg/) - see [Volumetric Light Scattering in three.js – Medium](https://medium.com/@andrew_b_berg/volumetric-light-scattering-in-three-js-6e1850680a41)
- [GPU Gems 3 - Chapter 13. Volumetric Light Scattering as a Post-Process](http://http.developer.nvidia.com/GPUGems3/gpugems3_ch13.html)
- [three.js extension to provide a volumetric spot light](http://jeromeetienne.github.io/threex.volumetricspotlight/examples/basic.html) - see [three.js extension to provide a volumetric spot light](https://github.com/jeromeetienne/threex.volumetricspotlight)
- [Doom 3 – Volumetric Glow | Simon schreibt.](https://simonschreibt.de/gat/doom-3-volumetric-glow/)
- [Light scattering with openGL shader](http://fabiensanglard.net/lightScattering/index.php)
- [Practical implementation of light scattering effects using epipolar sampling and 1D min/max binary trees - LightScatteringGDC2013_final.pdf](https://software.intel.com/sites/default/files/LightScatteringGDC2013_final.pdf)
- [Yzer development picture dump](http://yzergame.com/doomGlare.html) - [Doom 3 Glare effect in C++ : gamedev](https://www.reddit.com/r/gamedev/comments/1wukvd/doom_3_glare_effect_in_c/)
- [Fake Godray Shader «  Unity Coding – Unity3D](http://unitycoder.com/blog/2012/10/02/fake-godrays-shader/)

## HDR

- [High Dynamic Range Rendering - Graphics Programming and Theory - Articles - Articles - GameDev.net](https://www.gamedev.net/resources/_/technical/graphics-programming-and-theory/high-dynamic-range-rendering-r2108)
- [High-dynamic-range rendering — Wikipedia](https://en.wikipedia.org/wiki/High-dynamic-range_rendering)
- [Qu'est-ce que le High Dynamic Range (HDR) ? Une technologie pas si nouvelle ?](https://jeux.developpez.com/actu/105400/Qu-est-ce-que-le-High-Dynamic-Range-HDR-Une-technologie-pas-si-nouvelle/)
- [6800_Leagues_HDR.pdf - 6800_Leagues_HDR.pdf](ftp://download.nvidia.com/developer/presentations/2004/6800_Leagues/6800_Leagues_HDR.pdf) - see [6800_Leagues_HDR.pdf](6800_Leagues_HDR.pdf)

## Shading

Aka shadow, lighting

Dithered noise can be used to enhance, see [enhance](Enhance)

- [Shading — Wikipedia](https://en.wikipedia.org/wiki/Shading)
- [Dev. Blog of Edan Kwan-THREE.JS Advanced Tips : Shadow](http://blog.edankwan.com/post/three-js-advanced-tips-shadow)
- [Soft Shadow Mapping - Codeflow](http://codeflow.org/entries/2013/feb/15/soft-shadow-mapping/) - see https://github.com/pyalot/soft-shadow-mapping
- [New shadow demo with documented HLSL code | Moments in Graphics](http://momentsingraphics.de/?p=112)
- [i3D 2016 – Beyond Hard Shadows: Moment Shadow Maps for Single Scattering, Soft Shadows and Translucent Occluders | Moments in Graphics](http://momentsingraphics.de/?page_id=46)
- [Lightmap Generation - Made by Evan](http://madebyevan.com/shaders/lightmap/) - dynamically generates a combined ambient occlusion and direct illumination lightmap on the GPU
- [Inigo Quilez :: fractals, computer graphics, mathematics, demoscene and more](http://www.iquilezles.org/www/articles/sphereshadow/sphereshadow.htm) - sphere soft shadow
- [Inigo Quilez :: fractals, computer graphics, mathematics, demoscene and more](http://www.iquilezles.org/www/articles/rmshadows/rmshadows.htm) - free penumbra shadows for raymarching distance fields
- [Area Light Shader for three.js](http://jsfiddle.net/hh74z2ft/4/)
- [Exponential Cascaded Shadow Mapping with WebGL – Jean-Marc Le Roux](https://blogs.aerys.in/jeanmarc-leroux/2015/01/21/exponential-cascaded-shadow-mapping-with-webgl/) - use [Cascaded Shadow Maps](http://developer.download.nvidia.com/SDK/10.5/opengl/src/cascaded_shadow_maps/doc/cascaded_shadow_maps.pdf)
- [Shadows & Decals: D3D10 Techniques in Frostbite (GDC'09)](https://fr.slideshare.net/repii/02-g-d-c09-shadow-and-decals-frostbite-final3flat)
- [Shadow volume — Wikipedia](https://en.wikipedia.org/wiki/Shadow_volume) - see [The Theory of Stencil Shadow Volumes - Graphics Programming and Theory - Articles - Articles - GameDev.net](https://www.gamedev.net/resources/_/technical/graphics-programming-and-theory/the-theory-of-stencil-shadow-volumes-r1873)

> Signed Distance Fields are basically volume textures that are assigned to a mesh or height map etc.. The idea is to sample a number of locations around a mesh and calculate the shortest distance to any mesh point for each of these samples and finally store all of that in a volume texture.
> 
> Then during runtime you can sample the current location in this volume texture and have the minimum distance at the cost of a texture read!

- [Signed Distance Field Rendering Journey pt.1 | kosmonaut's blog](https://kosmonautblog.wordpress.com/2017/05/01/signed-distance-field-rendering-journey-pt-1/)

### Ambient lighting

Aka AO, SSAO, screen-space ambient occlusion

- [Ambient lighting - Shading — Wikipedia](https://en.wikipedia.org/wiki/Shading#Ambient_lighting)
- [GPU Gems - Chapter 17. Ambient Occlusio](http://http.developer.nvidia.com/GPUGems/gpugems_ch17.html)
- [Ambient occlusion — Wikipedia](https://en.wikipedia.org/wiki/Ambient_occlusion)
- [graphics - What is ambient occlusion? - Game Development Stack Exchange](http://gamedev.stackexchange.com/questions/23/what-is-ambient-occlusion/66638#66638)
- [Ambient Occlusion – Santiago Sanchez](https://santisanchez28.wordpress.com/2011/07/16/ambient-occlusion-2/)
- [Neural Network Ambient Occlusion](http://theorangeduck.com/page/neural-network-ambient-occlusion) and [nnao.pdf](http://theorangeduck.com/media/uploads/other_stuff/nnao.pdf) - NNAO, faster and more accurate than HBAO. "Code & Data" (`nnao_demo.zip`) contains SSAO, SSAO+, SAO, and HBAO implementation
- [Inigo Quilez :: fractals, computer graphics, mathematics, demoscene and more](http://www.iquilezles.org/www/articles/sphereao/sphereao.htm) - sphere ambient occlusion
- [Inigo Quilez :: fractals, computer graphics, mathematics, demoscene and more](http://www.iquilezles.org/www/articles/ssao/ssao.htm) - screen space ambient occlusion
- [Inigo Quilez :: fractals, computer graphics, mathematics, demoscene and more](http://www.iquilezles.org/www/articles/multiresaocc/multiresaocc.htm) - multiresolution ambient occlusion
- [Inigo Quilez :: fractals, computer graphics, mathematics, demoscene and more](http://www.iquilezles.org/www/articles/pervertexao/pervertexao.htm) - per vertex ambient occlusion
- https://mikolalysenko.github.io/vertex-ao/index.html - see [mikolalysenko/vertex-ao: Vertex based ambient occlusion calculation for meshes](https://github.com/mikolalysenko/vertex-ao)
- [SSDO](https://people.mpi-inf.mpg.de/~ritschel/Papers/SSDO.pdf) - Approximating Dynamic Global Illumination in Image Space. Screen-space directional occlusion (SSDO) is an improvement to SSAO.
- [Scalable Ambient Obscurance](http://graphics.cs.williams.edu/papers/SAOHPG12/) - GLSL SAO (Scalable Ambient Obscurance, more efficient method for computing SSAO), [WebGL GLSL SAO (Scalable Ambient Obscurance) fragment shader. SAO is a more efficient method for computing SSAO (Screen-Space Ambient Occlusion). Converts the g-buffer to an occlusion buffer which estimates local ambient occlusion at each fragment in screen-space. For details on the technique itself, see: McGuire et al \[12\] http://graphics.cs.williams.edu/papers/SAOHPG12/McGuire12SAO-talk.pdf](https://gist.github.com/fisch0920/6770311) WebGL implementation

## Cloud

Aka smoke, volumetric data (medical scans)

See [Volumetric billboard](#Volumetric billboard), [particles](#Particles) and [voxel](#Voxel)

- [Volumetric Ray Marcher * Distance Field Shadows - YouTube](https://www.youtube.com/watch?v=hWNX9jGEt8k) - distance fields can be used to add shadowing to volumetric effects https://twitter.com/ShaderBits/status/801498333172928512
- [Creating a Volumetric Ray Marcher](http://shaderbits.com/blog/creating-volumetric-ray-marcher)
- [Tiling within subUV or pseudo-volume textures](http://shaderbits.com/blog/tiling-within-subuv-or-volume-textures)
- [Volume Smoke - YouTube](https://www.youtube.com/watch?v=-mqAk5GmmiE)
- [Ray Marched Heightmaps](http://shaderbits.com/blog/ray-marched-heightmaps)
- [Clouds – Art of Luis](http://www.artofluis.com/3d-work/the-art-of-the-witness/clouds/)
- [Gamasutra - Let There be Clouds! Fast, Realistic Cloud-Rendering in Microsoft Flight Simulator 2004: A Century of Flight](http://www.gamasutra.com/view/feature/130434/let_there_be_clouds_fast_.php)
- [Microsoft Flight Simulator 2004 SDK Pack (All kits)](https://flyawaysimulation.com/downloads/files/2798/microsoft-flight-simulator-2004-sdk-pack-all-kits/)
- [Cloud Rendering](http://wayback.archive.org/web/20160519171509/http://ofb.net/~eggplant/clouds/)
- [\[RELEASE\] Nuaj', the 3D clouds simulator | Unity Community](https://forum.unity3d.com/threads/release-nuaj-the-3d-clouds-simulator.115825/)
- [Clouds](http://vterrain.org/Atmosphere/Clouds/)
- [image processing - WebGL earth : how to make clouds - Stack Overflow](https://stackoverflow.com/questions/31209237/webgl-earth-how-to-make-clouds)
- [Real-Time Cloud Rendering (Mark Harris)](http://www.markmark.net/clouds/)
- [Real-Time Realistic Cloud Rendering and Lighting - Game Programming - Articles - Articles - GameDev.net](https://www.gamedev.net/resources/_/technical/game-programming/real-time-realistic-cloud-rendering-and-lighting-r2273)
- [Inigo Quilez :: fractals, computer graphics, mathematics, demoscene and more](http://www.iquilezles.org/www/articles/dynclouds/dynclouds.htm) - dynamic clouds
- [Klemen Lozar's Online Portfolio](http://www.klemenlozar.com/frame-blending-with-motion-vectors/) - Frame Blending with Motion Vectors
- [Fallout 4 – The Mushroom Case | Simon schreibt.](https://simonschreibt.de/gat/fallout-4-the-mushroom-case/)
- [GDC 2005 - 008.rendering.practical_particle_lighting.pdf](http://www.roxlu.com/downloads/scholar/008.rendering.practical_particle_lighting.pdf)
- [Clouds](https://www.shadertoy.com/view/XslGRr)
- [Single-Pass Raycasting at The Little Grasshopper](http://prideout.net/blog/?p=64) - see [It is a fast library to deform voxel cubes embedded in tetrahedral meshes.](https://github.com/jgascon/VoxelDeformer) (simpleDemo, Volumetric Ray Casting Shader)
- [Volumetric Methods in Visual Effects (SIGGRAPH 2010 course) — Magnus Wrenninge](http://magnuswrenninge.com/volumetricmethods) and [VolumetricMethodsInVisualEffects_v25 - VolumetricMethodsInVisualEffects2010.pdf](http://magnuswrenninge.com/content/pubs/VolumetricMethodsInVisualEffects2010.pdf)
- [Real-Time Interactive Visualization of Volumetric Data with WebGL](http://demos.vicomtech.org/volren/)
- [Microsoft Word - RealTimeCloudRenderingForGames.doc - RTCloudsForGames_HarrisGDC2002.pdf](http://www.markmark.net/PDFs/RTCloudsForGames_HarrisGDC2002.pdf)
- [Clouds](http://mrdoob.com/lab/javascript/webgl/clouds/)

## Impostor

Aka sprite, billboard, Z-sprite

- [Sprite (computer graphics) — Wikipedia](https://en.wikipedia.org/wiki/Sprite_%28computer_graphics%29#Use_in_3D_rendering)

Example, Live2D Euclid (use multiple layers and project it using [Orthographic projection](Projection#Orthographic projection)): 

> Basically, it allows for certain details to be rendered in a way that isn't easy to do in 3D. eg: 2D-animated mouths when seen from the side
> Like lighting & shadows etc.

- [Orthographic projection — Wikipedia](https://en.wikipedia.org/wiki/Orthographic_projection)
- [Live2D Euclid animates 2D illustrations in rich 3D environments #DigInfo - YouTube](https://www.youtube.com/watch?v=8SMDLnC-cMU)
- [Introduction to Live2D Cubism Editor - YouTube](https://www.youtube.com/watch?v=XW6Yrxnn5dM)
- [Live2D Euclid 1 - 「作画」して生み出す、新次元の3D表現 - YouTube](https://www.youtube.com/watch?v=azQqmnqxuyk)
- [Euclid | Live2D](http://www.live2d.com/ja/products/euclid)

### Volumetric billboard

> Re: Volumetric Billboards
> 
> Postby Patapom » Tue Jul 19, 2011 4:25 pm
> I just finished implementing the technique in my renderer.
> Actually, it's not ray-marching of a volume but slicing of that volume.
> 
> Step 1 : Render a scene (anything really, as long as it's not too detailed) into a 3D texture (I actually rendered into 2 textures : diffuse|alpha and normal)
> Step 2 : Place several boxes in the world, each box the size of the original scene. Each box is assigned a material with the textures rendered in Step 1
> Step 3 : (todo for each frame)
> . Step 3.1 : Slice the entire space with planes orthogonal to the view direction in back to front order and with BLEND mode enabled
> . Step 3.2 : When a plane intersects the box, cut the box and generate geometry (using a Geometry Shader here)
> . Step 3.3 : For each pixel of the generated geometry, sample the 3D texture(s) and display using favorite lighting model
> 
> Nothing really complicated as you can see. The problem with the algorithm though is that you post many many individual draw calls ! Also, it's kind of really slow.
> 
> My advice : only use this technique at a distance, with low mip levels. Use (simplified) meshes for close view and traditional billboards for very far view. This technique is ideal for middle range LOD I think.
— [Irrlicht Engine • View topic - Volumetric Billboards](http://irrlicht.sourceforge.net/forum/viewtopic.php?t=38663#p254522)

> This is a PSA I tell everyone who is using particle effects: put some vertical lightness/darkness gradients on those particle bitmaps! It tends to look way more voluminous and less flat than an evenly lit particle bitmap.
— [commentaires de quitefunny sur A missile effect i've been working on for Air Brawl](http://www.reddit.com/r/Unity3D/comments/2bxry4/a_missile_effect_ive_been_working_on_for_air_brawl/cja5l1w)

- [Volumetric Clouds with Mega Particles](http://wayback.archive.org/web/20150928173920/http://www.inframez.com/events_volclouds_slide01.htm)
- [Render 3D Imposter Sprites | Unreal Engine](https://docs.unrealengine.com/latest/INT/Engine/Content/Tools/RenderToTextureTools/3/index.html)
- [Volumetric Billboards (Philippe Decaudin)](http://phildec.users.sourceforge.net/Research/VolumetricBillboards.php)
- [Simple Empty-Space Removal for Interactive Volume Rendering](http://www-ljk.imag.fr/Publications/Basilic/com.lmc.publi.PUBLI_Article@11aaaec1633_1358f03/index_en.html)
- [Volumetric Billboards (Philippe Decaudin)](http://wayback.archive.org/web/20150908180641/http://phildec.users.sourceforge.net/Research/VolumetricBillboards.php)
- [SG_2005_Real-Time_Rendering_of_Billboard_Plants_in_a_Dynamic_Lighting_Environment.pdf](http://www.p1xelcoder.com/resources/SG_2005_Real-Time_Rendering_of_Billboard_Plants_in_a_Dynamic_Lighting_Environment.pdf)
- [OpenGL - how to render object to 3D texture as a volumetric billboard - Stack Overflow](https://stackoverflow.com/questions/17504750/opengl-how-to-render-object-to-3d-texture-as-a-volumetric-billboard)
- [Imposteurs](http://damien.porquet.free.fr/msi/memoire/node19.php)
- [Volumetric Billboards](https://hal.inria.fr/inria-00402067/)
- [GPU Gems - Chapter 39. Volume Rendering Techniques](http://http.developer.nvidia.com/GPUGems/gpugems_ch39.html)
- [Gamasutra - Dynamic 2D Imposters: A Simple, Efficient DirectX 9 Implementation](http://www.gamasutra.com/view/feature/130911/dynamic_2d_imposters_a_simple_.php)
- [Simsville buildings - YouTube](https://www.youtube.com/watch?v=mtzz9FQ583A) - see [Decorating buildings in SimCity4](http://oceanquigley.blogspot.fr/2010/03/decorating-buildings-in-simcity4.html)

## Glass

- [Thick Glass with Floating-Point Textures at The Little Grasshopper](http://prideout.net/blog/?p=51)
- [FresnelGlass Recipe](http://prideout.net/recipes/FresnelGlass.html)

## Fog

- [Humus - 3D](http://www.humus.name/index.php?page=3D&ID=70) - Volumetric Fogging 2
- [Humus - 3D](http://www.humus.name/index.php?page=3D&ID=21) - Shadows in fog
- [Miles Macklin » Blog Archive » In-Scattering Demo](http://blog.mmacklin.com/2010/05/29/in-scattering-demo/)
- [Inigo Quilez :: fractals, computer graphics, mathematics, demoscene and more](http://www.iquilezles.org/www/articles/fog/fog.htm) - better fog
- [Inigo Quilez :: fractals, computer graphics, mathematics, demoscene and more](http://www.iquilezles.org/www/articles/spheredensity/spheredensity.htm) - sphere density

## Sand

Aka sand dune

See [Water](#Water)

- [Nighttime Sand Dunes](https://www.shadertoy.com/view/XtySRm)

## Water

- [No particles. Gerstner Wave shader + analytical splashes - YouTube](https://www.youtube.com/watch?v=OQ3D0Q5BlOs) - gerstner wave shader, utilizing distance fields for analytical splashes. All splashes are a single mesh here, using a masked flipbook texture. Splash flipbook texture. https://twitter.com/ShaderBits/status/827969354121805824
- [Humus - 3D](http://www.humus.name/index.php?page=3D&ID=42)
- [WebGL Water](http://madebyevan.com/webgl-water/) - see https://github.com/evanw/webgl-water
- [Rendering Water with WebGL](https://29a.ch/slides/2012/webglwater/)
- [Realistic water shader for Three.js](https://github.com/jbouny/ocean) - see [Ocean - Jérémy BOUNY](http://jeremybouny.fr/ocean/demo/))
- [Seascape](https://www.shadertoy.com/view/Ms2SD1) - see `Seascape.glsl`
- [Tileable Water Caustic](https://www.shadertoy.com/view/MdlXz8)

### Wave

	amplitude * Math.sin(((2 * Math.PI) / wavelength) * position - (frequency * time) + phase) + offset;

* `amplitude`: Deviation from center (aka. height of the wave)
* `frequency`: Radians per second (aka. speed of the wave)
* `offset`: Shifting the wave’s position from center (usually a y-offset)
* `phase`: Shifting the wave by time
* `wavelength`: Distance between waves
* `position`: Position at which to calculate the state of the wave (usually an x-position)
* `time`: A point of time at which to calculate the wave

- [Ocean Wave Simulation](http://david.li/waves/) - see https://github.com/dli/waves
- [Water ripple FX with Canvas and Javascript](http://code.almeros.com/water-ripple-canvas-and-javascript) - see [Water canvas by Almer Thie](http://code.almeros.com/code-examples/water-effect-canvas/)
- [Inigo Quilez :: fractals, computer graphics, mathematics, demoscene and more](http://www.iquilezles.org/www/articles/simplewater/simplewater.htm) - water

## Wind

Aka flag effect

- [Humus - 3D](http://www.humus.name/index.php?page=3D&ID=46)
- [Noise](Noise) + displacement map (baseX=width, baseY=200, numOctaves=1, randomSeed=500, stitch=false, fractalNoise=true, colored, +perlinOffset)

## Distortion

Aka flame, heat, heat haze, water reflection

- [=^.^=](https://yomotsu.neocities.org/1/) - ESO inspired heathaze effect in #threejs w/o post-processing. See "Akihiro Oyamada Demo"
- [Heat Distortion Effect | Demo 1: Desert Heat](https://tympanus.net/Tutorials/HeatDistortionEffect/) - see [Animated Heat Distortion Effects with WebGL | Codrops](https://tympanus.net/codrops/2016/05/03/animated-heat-distortion-effects-webgl/)

## Planet

See also [volumetric light](#Volumetric light) (for eclipse effect) and [projection](Projection)

- [Mirage — Wikipedia](https://en.wikipedia.org/wiki/Mirage)
- [Globe Viewer](http://k9.github.io/globe-viewer/index.html), [Globe Viewer](http://k9.github.io/globe-viewer-svg-simple/index.html) and [Globe Viewer](http://k9.github.io/globe-viewer-svg-simple/index.html) - see https://github.com/k9/globe-viewer and https://github.com/k9/k9.github.com
- [xg - earth's seasons](http://alteredqualia.com/xg/examples/earth_seasons.html)
- [xg - jupiter atmosphere](http://alteredqualia.com/xg/examples/jupiter.html) - Use a video as texture
- [xg - nebula artefact](http://alteredqualia.com/xg/examples/nebula_artefact.html)
- [Beautiful Pixels: Gamma Correct Lighting, On The Moon!](http://beautifulpixels.blogspot.fr/2009/10/gamma-correct-lighting-on-moon.html)

### Atmospheric scattering

Aka sky

Add a bit fog effect

- [The MoviePass Quest](https://medium.com/@Falgan/the-moviepass-quest-c395e656a813) - Atmospheric scattering and scattering asteroids see [valerian](http://spacevr.makemepulse.com/expe.html?hd=1)
- [Simulating the Colors of the Sky (Simulating the Colors of the Sky)](http://www.scratchapixel.com/lessons/procedural-generation-virtual-worlds/simulating-sky)
- [Advanced WebGL - Part 2: Sky Rendering - Codeflow](http://codeflow.org/entries/2011/apr/13/advanced-webgl-part-2-sky-rendering/)
- [Atmospheric Scattering Sample](https://www.shadertoy.com/view/lslXDr) - see `test.glsl`
- [GPU Gems - Chapter 16. Accurate Atmospheric Scattering](http://http.developer.nvidia.com/GPUGems2/gpugems2_chapter16.html)
- [day & night cycle sky shader for you - DirectX and XNA - GameDev.net](https://www.gamedev.net/topic/538429-day--night-cycle-sky-shader-for-you/)
- [Simple Sky Shader - jsdo.it - Share JavaScript, HTML5 and CSS](http://jsdo.it/zz85/ooUZ)
- [Atmospheric Scattering](http://simonwallner.at/project/atmospheric-scattering/) - see https://github.com/SimonWallner/kocmoc-demo/tree/RTVIS and `kocmoc-demo atmospheric_scattering.zip`

## Material

- Different type of material in ThreeJS https://github.com/mrdoob/three.js/issues/10235#issuecomment-263163446
- [Packing Lightmaps](Arrange space)
- [3d Max Help: Car Paint Material/Shader (mental ray)](http://docs.autodesk.com/3DSMAX/15/ENU/3ds-Max-Help/index.html?url=files/GUID-1CD21856-588A-4A05-AC0A-88489F5F9C84.htm,topicNumber=d30e378481) - Car paint

### Materials parameters

Ambient color : Ambient color is the color of an object where it is in shadow. This color is what the object reflects when illuminated by ambient light rather than direct light.
Diffuse color :Diffuse color is the most instinctive meaning of the color of an object. It is that essential color that the object reveals under pure white light. It is perceived as the color of the object itself rather than a reflection of the light.
Emissive color : This is the self-illumination color an object has.
Specular color :Specular color is the color of the light of a specular reflection (specular reflection is the type of reflection that is characteristic of light reflected from a shiny surface).

Material 	index of refraction
Vacuum		1
Air			~1
Glass		1.5
Ice			1.3
Diamond		2.42
Water		1.33
Ruby		1.77
Emerald		1.57

Material 			Property 				rgba / percent
Brass				ambient					0.329412 0.223529 0.027451 1
					diffuse					0.780392 0.568627 0.113725 1
					specular				0.992157 0.941176 0.807843 1
					shininess				27.8974
Bronze				ambient					0.2125 0.1275 0.054 1
					diffuse					0.714 0.4284 0.18144 1
					specular				0.393548 0.271906 0.166721 1
					shininess				25.6
Polished Bronze		ambient					0.25 0.148 0.06475 1
					diffuse					0.4 0.2368 0.1036 1
					specular				0.774597 0.458561 0.200621 1
					shininess				76.8
Chrome				ambient					0.25 0.25 0.25 1
					diffuse					0.4 0.4 0.4 1
					specular				0.774597 0.774597 0.774597 1
					shininess				76.8
Copper				ambient					0.19125 0.0735 0.0225 1
					diffuse					0.7038 0.27048 0.0828 1
					specular				0.256777 0.137622 0.086014 1
					shininess				12.8
Polished Copper		ambient					0.2295 0.08825 0.0275 1
					diffuse					0.5508 0.2118 0.066 1
					specular				0.580594 0.223257 0.0695701 1
					shininess				51.2
Gold				ambient					0.24725 0.1995 0.0745 1
					diffuse					0.75164 0.60648 0.22648 1
					specular				0.628281 0.555802 0.366065 1
					shininess				51.2
Polished Gold		ambient					0.24725 0.2245 0.0645 1
					diffuse					0.34615 0.3143 0.0903 1
					specular				0.797357 0.723991 0.208006 1
					shininess				83.2
Pewter				ambient					0.105882 0.058824 0.113725 1
					diffuse					0.427451 0.470588 0.541176 1
					specular				0.333333 0.333333 0.521569 1
					shininess				9.84615
Silver				ambient					0.19225 0.19225 0.19225 1
					diffuse					0.50754 0.50754 0.50754 1
					specular				0.508273 0.508273 0.508273 1
					shininess				51.2
Polished Silver		ambient					0.23125 0.23125 0.23125 1
					diffuse					0.2775 0.2775 0.2775 1
					specular				0.773911 0.773911 0.773911 1
					shininess				89.6
Emerald				ambient					0.0215 0.1745 0.0215 0.55
					diffuse					0.07568 0.61424 0.07568 0.55
					specular				0.633 0.727811 0.633 0.55
					shininess				76.8
Jade				ambient					0.135 0.2225 0.1575 0.95
					diffuse					0.54 0.89 0.63 0.95
					specular				0.316228 0.316228 0.316228 0.95
					shininess				12.8
Obsidian			ambient					0.05375 0.05 0.06625 0.82
					diffuse					0.18275 0.17 0.22525 0.82
					specular				0.332741 0.328634 0.346435 0.82
					shininess				38.4
Pearl				ambient					0.25 0.20725 0.20725 0.922
					diffuse					1 0.829 0.829 0.922
					specular				0.296648 0.296648 0.296648 0.922
					shininess				11.264
Ruby				ambient					0.1745 0.01175 0.01175 0.55
					diffuse					0.61424 0.04136 0.04136 0.55
					specular				0.727811 0.626959 0.626959 0.55
					shininess				76.8
Turquoise			ambient					0.1 0.18725 0.1745 0.8
					diffuse					0.396 0.74151 0.69102 0.8
					specular				0.297254 0.30829 0.306678 0.8
					shininess				12.8
Black Plastic		ambient					0 0 0 1
					diffuse					0.01 0.01 0.01 1
					specular				0.5 0.5 0.5 1
					shininess				32
Black Rubber		ambient					0.02 0.02 0.02 1 0
					diffuse					0.01 0.01 0.01 1 undefined
					specular				0.4 0.4 0.4 1 undefined
					shininess				10

- [Common 3D materials parameters](http://www.barradeau.com/nicoptere/dump/materials.html)
- [OpenGL/VRML Materials](http://devernay.free.fr/cours/opengl/materials.html)
- [gl-materials.ads](http://globe3d.sourceforge.net/g3d_html/gl-materials__ads.htm)
- [Real 3D Tutorials: Tutorial 8 - Materials that shine](http://www.real3dtutorials.com/tut00008.php)

### Reflection

[Voxel](#Voxel) can be used for reflection

- [Advanced WebGL - Part 3: Irradiance Environment Map - Codeflow](http://codeflow.org/entries/2011/apr/18/advanced-webgl-part-3-irradiance-environment-map/)
- [GPU Gems - Chapter 10. Real-Time Computation of Dynamic Irradiance Environment Maps](http://http.developer.nvidia.com/GPUGems2/gpugems2_chapter10.html)
- [WebGL Deferred Irradiance Volumes - Codeflow](http://codeflow.org/entries/2012/aug/25/webgl-deferred-irradiance-volumes/)

### Wireframe

- [Easy wireframe display with barycentric coordinates - Codeflow](http://codeflow.org/entries/2012/aug/02/easy-wireframe-display-with-barycentric-coordinates/))

## Texture

Use bleeding

![UV Coordinates   Alternativaplatform](Texture/UV%20coordinates%20-%20alternativaplatform.gif)

![performance comparison: polygon trimming vs rectangular trimming](https://cdn.codeandweb.com/blog/2015/10/01/cocos2d-x-performance-optimization/polygon-trimming.png)

Performances:

- [Performance optimization for cocos2d-x using polygon sprite meshes](https://www.codeandweb.com/texturepacker/tutorials/cocos2d-x-performance-optimization) - Trim mesh to reduce paint time

See also [Triplanar Mapping](#Triplanar Shader)

- [Luos's Free Noise Textures (for vfx)](https://gumroad.com/l/FreeNoise) - Noise textures

### Virtual texture

Aka texture streaming, mega texture

Usefull for panet environment, highly detailed textures, rich environment, etc.

- [id Tech 4 — Wikipedia](https://en.wikipedia.org/wiki/Id_Tech_4#MegaTexture_rendering_technology)
- [Sparse Virtual Textures](http://silverspaceship.com/src/svt/)
- [benvanik/Hiranipra- Experiments in WebGL and a toy web game sandbox](https://github.com/benvanik/Hiranipra/tree/dev)
- [elfrank/virtual-texturing- Virtual Texturing for three.js](https://github.com/elfrank/virtual-texturing)
- [Hiranipra MegaTextures Experiment](http://noxa.org/old/hiranipra/Experiments/MegaTextures/index.html)
- [rendering - How can virtual texturing actually be efficient? - Computer Graphics Stack Exchange](http://computergraphics.stackexchange.com/questions/1768/how-can-virtual-texturing-actually-be-efficient)
- [Virtual Texture Demo - Brad Blanchard](http://linedef.com/virtual-texture-demo.html)
- [Megatextures in Rage | RenderingPipeline](http://renderingpipeline.com/2012/03/megatextures-in-rage/)
- [MegaTextures in WebGL « Various Oddities](http://www.noxa.org/blog/2009/11/29/megatextures-in-webgl-2/)
- [Microsoft Word - Chapter02-Mittring-Advanced_Virtual_Texture_Topics.docx - Chapter02-Mittring-Advanced_Virtual_Texture_Topics.pdf](https://developer.amd.com/wordpress/media/2013/01/Chapter02-Mittring-Advanced_Virtual_Texture_Topics.pdf)
- [Real-Time Texture Streaming & Decompression - Real-Time-Texture-Streaming-&-Decompression.pdf](http://mrelusive.com/publications/papers/Real-Time-Texture-Streaming-&-Decompression.pdf) - [Real-Time Texture Streaming & Decompression | Intel® Software](https://software.intel.com/en-us/articles/real-time-texture-streaming-decompression)
- [WebGL Earth Documentation - 2 Real-time texturing methods](http://data.webglearth.com/doc/webgl-earthch2.html) - https://github.com/webglearth

Virtual Texturing - Antelope Island:

> For a long time games have used textures to add surface details and diversity to their virtual worlds. These textures usually consist of a basic set of different surface appearances which are then composited at run-time by shaders to calculate the final surface appearance.
> 
> Recently there has been an increased interest in virtual texturing technologies. Virtual texturing allows very large textures (in the order of one gigapixel) to be applied to the game's geometry while still remaining within the limits of today's hardware. This allows far more varied worlds than can be achieved with composing tiling textures at a lower or comparable render cost.
> 
> This video demonstrates our virtual texturing system. Our system uses NVIDIA's CUDA(Compute Unified Device Architecture) platform to reduce CPU work to a minimum and efficiently streams data between system memory and GPU memory. Additionally the data is transcoded on the fly using both the CPU (SSE2) and GPU(CUDA) to accelerate this as much as possible.
> 
> The technical details and source code of our system are available in the following publication:
> C. Hollemeersch, B. Pieters, P. Lambert, R. Van de Walle. Accelerating virtual texturing using CUDA, In GPU Pro : advanced rendering techniques, Pages 623-641, AK Peters, 2010
> 
> The texture data used in this demo was made available by Utah's State Geographic Information Database (see http://gis.utah.gov/hro2006).
> 
> http://gis.utah.gov/data/aerial-photography/2006-hro-1-foot-color-orthophotography/
> ftp://ftp.agrc.utah.gov/UtahSGID_Vector/UTM12_NAD83/INDICES/UnpackagedData/HRO2006/_Statewide/HRO2006_shp.zip
> ftp://ftp.agrc.utah.gov/Imagery/HRO2006/HRO2006_Index.zip
> ftp://ftp.agrc.utah.gov/Imagery/HRO2006/

- [Virtual Texturing - Antelope Island - YouTube](https://www.youtube.com/watch?v=Rg6FE-HVJ44)
- [Accelerating Virtual Texturing Using CUDA - Semantic Scholar](https://www.semanticscholar.org/paper/Accelerating-Virtual-Texturing-Using-CUDA-Hollemeersch-Pieters/6a523c92dc123367f814721c5f26e540645e096b)
- [Real-Time Visualizations of Gigapixel Texture Data Sets Using HTML5](http://wayback.archive.org/web/20130525001905/http://schumann.elis.ugent.be/) (not working demo)
- [Chrome Experiments - Antelope Island by Charles Hollemeersch](https://www.chromeexperiments.com/experiment/antelope-island)
- [Virtual Texturing in HTML5 using WebGL – Charles Hollemeersch \ Blog](http://charles.hollemeersch.net/2012/07/27/virtual-texturing-in-html5-using-webgl/)

### Monochrome textures in separated channels

Use monochrome textures will be colorized render time. Allow to store 4 texture inside same RGBA texture

Reduce Video memory usage, limit texture upload

![Channels layout](http://www.torfrick.com/Art/UDKLab/Layout.jpg)
![Tile explain](http://torfrick.com/Art/WIP/TileExplain.jpg)

> Instead, I came up with the solution that in one of the UV sets, I moved the polygons that I wanted to change color on one UV-grid to the side, and then used a small area of one of the color channels as a mask that I scaled up in the material editor.

> - UV1: normal map and ambient occlusion
> - UV2: decals.
> - UV3: colors
> - UV4: was used for Light Maps and the tiling noise texture

- [Tor Frick - 3D artist](http://www.torfrick.com/info/lab.html) - See [Amazing One - Texture Environment](https://www.unrealengine.com/showcase/amazing-one-texture-enviroment) and [One-Texture Environment - Dayward Inc. on Vimeo](https://vimeo.com/42336299)
- [An exercise in modular textures - Scifi lab UDK — polycount](http://polycount.com/discussion/comment/1443681/#Comment_1443681)
- [\[UDK\] Oil Rig Observation Outpost - Page 2 — polycount](http://polycount.com/discussion/comment/1588220/#Comment_1588220)
- [Lunar City 7 - One Texture Environment — polycount](http://polycount.com/discussion/119615/lunar-city-7-one-texture-environment)

### Texture repetition

Aka texture variation

- [Inigo Quilez :: fractals, computer graphics, mathematics, demoscene and more](http://www.iquilezles.org/www/articles/texturerepetition/texturerepetition.htm) - texture repetition
- [Texture variation V](https://www.shadertoy.com/view/Xtl3zf)
 
	// Created by inigo quilez - iq/2017
	// License Creative Commons Attribution-ShareAlike 3.0 Unported
	// https://creativecommons.org/licenses/by-sa/3.0/
	
	// One way to avoid texture tile repetition one using one small texture to cover a huge area.
	// Basically, it creates 8 different offsets for the texture and picks two to interpolate
	// between.
	//
	// Unlike previous methods that tile space (https://www.shadertoy.com/view/lt2GDd or
	// https://www.shadertoy.com/view/4tsGzf), this one uses a random low frequency texture
	// (cache friendly) to pick the actual texture's offset.
	//
	// Also, this one mipmaps to something (ugly, but that's better than not having mipmaps
	// at all like in previous methods)
	
	
	float sum( vec3 v ) { return v.x+v.y+v.z; }
	
	vec3 textureNoTile( in vec2 x, float v )
	{
		float k = texture( iChannel1, 0.005*x ).x; // cheap (cache friendly) lookup
	
		float l = k*8.0;
		float i = floor( l );
		float f = fract( l );
	
		vec2 offa = sin(vec2(3.0,7.0)*(i+0.0)); // can replace with any other hash
		vec2 offb = sin(vec2(3.0,7.0)*(i+1.0)); // can replace with any other hash
	
		vec2 dx = dFdx(x), dy = dFdy(x);
	
		vec3 cola = textureGrad( iChannel0, x + v*offa, dx, dy ).xyz;
		vec3 colb = textureGrad( iChannel0, x + v*offb, dx, dy ).xyz;
	
		return mix( cola, colb, smoothstep(0.2,0.8,f-0.1*sum(cola-colb)) );
	}
	
	void mainImage( out vec4 fragColor, in vec2 fragCoord )
	{
		vec2 uv = fragCoord.xy / iResolution.xx;
	
		float f = smoothstep( 0.4, 0.6, sin(iGlobalTime	) );
		float s = smoothstep( 0.4, 0.6, sin(iGlobalTime*0.5) );
		
		vec3 col = textureNoTile( (4.0 + 6.0*s)*uv, f );
	
		fragColor = vec4( col, 1.0 );
	}

### Perspective texture correction

See [resample](Resample)

- [OpenGL/VRML Materials](http://devernay.free.fr/cours/opengl/materials.html)
- Perspective texture correction [Perspective Texturemapping](http://www.lysator.liu.se/~mikaelk/doc/perspectivetexture/)

### Procedural texture

See [Random, noise and dithering - Procedural](Random, noise and dithering#Procedural)

- [TexGen - AngelCode.com](http://www.angelcode.com/texgen/)
- [blogorrhea: Procedural Textures in HTML5 Canvas](http://asserttrue.blogspot.fr/2012/01/procedural-textures-in-html5-canvas.html) - see [Procedural Textures](Procedural Textures.html)
- [WaveFunctionCollapse](https://github.com/mxgmn/WaveFunctionCollapse) - Bitmap & tilemap generation from a single example with the help of ideas from quantum mechanics
- [ConvChain](https://github.com/mxgmn/ConvChain) -  Bitmap generation from a single example with convolutions and MCMC
- [pix2pix](https://github.com/phillipi/pix2pix) and [pix2pix-tensorflow](https://github.com/affinelayer/pix2pix-tensorflow) (tensorflow port) - Image-to-image translation using conditional adversarial nets. See [Image-to-Image Demo - Affine Layer](http://affinelayer.com/pixsrv/)
- [170311](https://bit101.github.io/lab/dailies/170311.html) - procedural map

### Texture baking

Aka spritesheet

- [Layout, pack — Arrange space](Arrange space)
- [Whizzkids corner: Render to Texture, or Texture baking in 3dStudio max for Papervision3d](http://whizzkid74.blogspot.fr/2008/05/render-to-texture-or-texture-baking-in.html)
- [Light baking and automatic UV unwrap with Max - Blog - (BKcore) Thibaut Despoulain](http://bkcore.com/blog/3d/light-baking-auto-uv-unwrap-max.html)
- [Introduction to Cycles Baking - YouTube](https://www.youtube.com/watch?v=sB09T--_ZvU&list=UUOKHwx1VCdgnxwbjyb9Iu1g)
- [TexTools](http://renderhjs.net/textools/) - 3dsMax plugin

## Rendering text

See also [spline rasterization](Spline#Rasterization)

> Microsoft did patent the Loop-Blinn curve-filling technique, but a quick read makes it look like it only applies to outlines defined in part by cubic Bezier curves (http://www.google.com/patents/US20070097123).

- [It’s 2015 and drawing text is still hard (WebGL, ThreeJS) | Engineering Blog](https://www.eventbrite.com/engineering/its-2015-and-drawing-text-is-still-hard-webgl-threejs/) see also [Signed Distance Fields](#Signed Distance Fields)
- [Theta](http://thetamath.com/app/) - This is a simple web app that graphs an equation. See https://github.com/evanw/theta and [Easy Scalable Text Rendering on the GPU – Medium](https://medium.com/@evanwallace/easy-scalable-text-rendering-on-the-gpu-c3f4d782c5ac)
- [GPU Font Rendering](https://github.com/ds-hwang/wiki/wiki/GPU-Font-Rendering) - reference list about text rendering on GPU
- [Android’s Font Renderer – Medium](https://medium.com/@romainguy/androids-font-renderer-c368bbde87d9)
- [Higher Quality 2D Text Rendering](http://jcgt.org/published/0002/01/04/paper.pdf)
- [Anti-Grain Geometry - Texts Rasterization Exposures](http://www.antigrain.com/research/font_rasterization/)
- [Vector Texture Maps on the GPU](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.101.2464&rep=rep1&type=pdf) - This paper presents VTMs (Vector Texture Maps), a novel representation of vector images that can be used as a texture by the GPU for real-time rendering.
- [Rendering Text in WebVR  |  Web  |  Google Developers](https://developers.google.com/web/showcase/2017/within) - Article about use case of rendering text in a VR context (3D content with GPU acceleration). One of the best option to use for this case is [SDF](#Signed Distance Fields).
- [Inside the fastest font renderer in the world – Medium](https://medium.com/@raphlinus/inside-the-fastest-font-renderer-in-the-world-75ae5270c445) - CPU font renderer using SIMD written in Rust. See https://github.com/google/font-rs
- [Pathfinder, a fast GPU-based font rasterizer in Rust - pcwalton](http://pcwalton.github.io/blog/2017/02/14/pathfinder/) - A fast, practical GPU rasterizer for OpenType fonts. See https://github.com/pcwalton/pathfinder
- [Texture-Based Text rendering](https://cscheid.github.io/lux/demos/texture_text/texture_text.html) - Texture-based text rendering infrastructure includes an adaptive antialiasing algorithm meant to produce better results at very low resolutions (or very deep zooms). See https://github.com/cscheid/lux/tree/master/demos/texture_text

### Text outline

- [Outlines and other Dynamic Text pimping | Neuro Productions](http://wayback.archive.org/web/20160322114909/http://www.neuroproductions.be/experiments/outlines-dynamic-text/)
- http://wayback.archive.org/web/20150320071957/http://www.neuroproductions.be/uploads/blog/examples/fontfun/TextTest.swf
- http://wayback.archive.org/web/20150320063642/http://www.neuroproductions.be/uploads/blog/examples/fontfun/TextTest2.swf

### Paper and ink effect

Text erodes, fades, glows, drips, glistens, absorbs...

- [Material Design on the GPU](https://mattdesl.svbtle.com/material-design-on-the-gpu)
- [physical-text - @mattdesl](http://mattdesl.github.io/physical-text/index.html)
- https://github.com/mattdesl/physical-text
- https://twitter.com/mattdesl/status/594344674367819776

### Grid bézier vector texture

> let the GPU render [the glyph] from the original vector data

> We can chop up each glyph into a grid and in each cell store just the bezier curves that intersect it

- [War and Peace and WebGL · Will Dobbie](http://wdobbie.com/post/war-and-peace-and-webgl/)
	See [Resolution independent GPU text rendering demo](http://wdobbie.com/warandpeace/)
	
	> The .bmp is gzipped to 7MB. I'm not using png because some browsers will premultiply alpha, and this corrupts the vector texture atlas. The file is just downloaded as regular binary data and processed in javascript.
	
	See also
	
	- [Resolution independent GPU text rendering demo](http://wdobbie.com/pdf/)
	- [GPU text rendering with vector textures · Will Dobbie](http://wdobbie.com/post/gpu-text-rendering-with-vector-textures/)
	- [Implementation notes: GPU text rendering with vector textures · Will Dobbie](http://wdobbie.com/post/gpu-text-rendering-with-vector-textures-details/)

### Signed Distance Fields

Use bitmap data:

- [Text rendering in OpenGL – hack.chrons](http://hack.chrons.me/opengl-text-rendering/)
- [Improved Alpha-Tested Magniﬁcation for Vector Textures and Special Effects paper](http://www.valvesoftware.com/publications/2007/SIGGRAPH2007_AlphaTestedMagnification.pdf) by Chris Green of Valve in the SIGGRAPH 2007
- [Drawing Text with Signed Distance Fields in Mapbox GL | Mapbox](https://www.mapbox.com/blog/text-signed-distance-fields/)
- https://github.com/eventbrite/cartogram/blob/master/src/scripts/fnt_to_json_readme.md and https://github.com/eventbrite/cartogram/blob/master/src/shapes/text_sdf.js
- https://mapbox.s3.amazonaws.com/kkaefer/sdf/index.html
- [Distance field fonts · libgdx/libgdx Wiki](https://github.com/libgdx/libgdx/wiki/Distance-field-fonts)
- [renders BMFont files in ThreeJS with word-wrapping](https://github.com/Jam3/three-bmfont-text)
- [Using better looking bitmap fonts (SDF Fonts) - Community Answers](https://answers.madewithmarmalade.com/questions/19455/using-better-looking-bitmap-fonts-sdf-fonts.html)
- Text rendering with vector textures
	- [War and Peace and WebGL · Will Dobbie](http://wdobbie.com/post/war-and-peace-and-webgl/) and https://disqus.com/embed/comments/?base=default&version=62cc70f7a67f1caa78581a1ef0bdf448&f=wdobbie&t_u=http%3A%2F%2Fwdobbie.com%2Fpost%2Fwar-and-peace-and-webgl%2F&t_d=War%20and%20Peace%20and%20WebGL&t_t=War%20and%20Peace%20and%20WebGL&s_o=default
	- [GPU text rendering with vector textures · Will Dobbie](http://wdobbie.com/post/gpu-text-rendering-with-vector-textures/) and https://disqus.com/embed/comments/?base=default&version=62cc70f7a67f1caa78581a1ef0bdf448&f=wdobbie&t_u=http%3A%2F%2Fwdobbie.com%2Fpost%2Fgpu-text-rendering-with-vector-textures%2F&t_d=GPU%20text%20rendering%20with%20vector%20textures&t_t=GPU%20text%20rendering%20with%20vector%20textures&s_o=default
- https://github.com/mattdesl/gl-sprite-text

Use vector data:

- [GLyphy](https://github.com/behdad/glyphy) - GLyphy: high-quality glyph rendering using OpenGL ES2 shaders. See also https://vimeo.com/83732058 and [glyphy_slides.pdf](http://behdad.org/glyphy_slides.pdf)
	
#### Multi-channel Signed Distance Field

Aka MSDF

- [Multi-channel signed distance field generator](https://github.com/Chlumsky/msdfgen)
- [texture - Sharp Corners with Signed Distance Fields Fonts - Computer Graphics Stack Exchange](http://computergraphics.stackexchange.com/questions/306/sharp-corners-with-signed-distance-fields-fonts/2151#2151)
- [LambdaCube Font Engine ](https://github.com/cobbpg/lafonten) - see [Playing around with distance field font rendering | LambdaCube 3D](https://lambdacube3d.wordpress.com/2014/11/12/playing-around-with-font-rendering/)
- [renders BMFont files in ThreeJS with word-wrapping](https://github.com/Jam3/three-bmfont-text) - support MSDF. See https://github.com/Jam3/three-bmfont-text/blob/master/docs/sdf.md

## Anti-aliasing

- [Edge-distance anti-aliasing](https://abandonedwig.info/edge-distance-anti-aliasing/demo.html) - see [Edge-distance anti-aliasing | Woohoo](https://abandonedwig.info/blog/2013/02/24/edge-distance-anti-aliasing.html)
- [ClearType — Wikipedia](https://en.wikipedia.org/wiki/ClearType)
- [Category:Anti-aliasing — Wikimedia Commons](https://commons.wikimedia.org/wiki/Category:Anti-aliasing)
- [Drawing antialiased circles in OpenGL • rubendv.be](https://rubendv.be/blog/opengl/drawing-antialiased-circles-in-opengl/)
- [Feedback Applet Ported to WebGL « null program](http://nullprogram.com/blog/2014/06/21/#anti-aliasing)
- aastep
	- [anti-alias smoothstep utility function](https://github.com/stackgl/glsl-aastep) - aastep
	 
		float aastep(float threshold, float value) {
		  #ifdef GL_OES_standard_derivatives
			float afwidth = length(vec2(dFdx(value), dFdy(value))) * 0.70710678118654757;
			return smoothstep(threshold-afwidth, threshold+afwidth, value);
		  #else
			return step(threshold, value);
		  #endif  
		}

		# A full example of 2D circle rendering
		precision highp float;
		
		#ifdef GL_OES_standard_derivatives
		#extension GL_OES_standard_derivatives : enable
		#endif
		
		#include aastep
		
		uniform float iGlobalTime;
		uniform vec3  iResolution;
		
		void main() {
			//centered texture coordinates
			vec2 uv = vec2(gl_FragCoord.xy / iResolution.xy) - 0.5;
			
			//correct aspect
			uv.x *= iResolution.x / iResolution.y;
			
			//animate zoom
			uv /= sin(iGlobalTime * 0.2); 
			
			//radial distance
			float len = length(uv);
			
			//anti-alias
			len = aastep(0.5, len);
			
			gl_FragColor.rgb = vec3(len);
			gl_FragColor.a   = 1.0;
		}

### Line anti-aliasing

![Wire aliasing](http://www.humus.name/3D/PhoneWireAAComp.png)

> The idea is to adjust the radius of the wire to make sure it does not get smaller than a pixel wide. If the wire's radius would make it smaller than a pixel, it clamps the width to a pixel and instead fades with an alpha value corresponding to the radius reduction ratio. For example, if the wire is deemed to be half a pixel large at current distance, it clamps width to a full pixel and sets coverage to 0.5 instead. While the technique solves the problem of aliasing due to thin geometry, it does not address the general problem of jaggies; however, your regular MSAA will take care of that. With both enabled you get a very natural looking wire at any distance.
> 
> A similar approach could likely be used on other aliasing prone geometry based on thin geometry, such as antenna towers, pipes and railings. 
— [Humus - 3D](http://www.humus.name/index.php?page=3D&ID=89)

- [GPU Gems - Chapter 22. Fast Prefiltered Lines](http://http.developer.nvidia.com/GPUGems2/gpugems2_chapter22.html)

## Render line

For anti-aliasing, see [line anti-aliasing](#Line anti-aliasing)

- [Line drawing on a grid](http://www.redblobgames.com/grids/line-drawing.html)

## Rendering process

Aka rasterization, render pipeline

![Gl1 Pipeline 01 - duriansoftware](Rendering%20process/gl1-pipeline-01.png)
![Gl1 Triangle Assembly 01 - duriansoftware](Rendering%20process/gl1-triangle-assembly-01.png)
![PV3D Render Pipeline](Rendering%20process/PV3D%20render%20pipeline.png)
![3D Transformation pipline](http://aosabook.org/en/500L/modeller-images/newtranspipe.png)

- [Render Hell 2.0 | Simon schreibt.](https://simonschreibt.de/gat/renderhell/)
- [GPU Performance for Game Artists | FragmentBuffer](http://fragmentbuffer.com/gpu-performance-for-game-artists/)
- [DOOM (2016) - Graphics Study - Adrian Courrèges](http://www.adriancourreges.com/blog/2016/09/09/doom-2016-graphics-study/) - Very complete infos about rendering process of DOOM (2016)
- [Guardians of Atlas - Rendering and Frame Breakdown - Blog - (BKcore) Thibaut Despoulain](http://bkcore.com/blog/3d/guardians-of-atlas-rendering-frame-breakdown.html)
- [An intro to modern OpenGL. Table of Contents](http://duriansoftware.com/joe/An-intro-to-modern-OpenGL.-Table-of-Contents.html) - see https://github.com/jckarter/hello-gl
- [Les cartes graphiques/Les cartes accélératrices 3D — Wikilivres](https://fr.wikibooks.org/wiki/Les_cartes_graphiques/Les_cartes_acc%C3%A9l%C3%A9ratrices_3D)
- [OpenGL Core Tutorial (F. Harrouet, ENIB)](http://www.enib.fr/~harrouet/Data/Courses/OpenGlCoreTutorial/OpenGlCoreTutorial.html)
- [Rasterization: a Practical Implementation (An Overview of the Rasterization Algorithm)](https://www.scratchapixel.com/lessons/3d-basic-rendering/rasterization-practical-implementation/overview-rasterization-algorithm)
- [Rasterization: a Practical Implementation (The Projection Stage)](https://www.scratchapixel.com/lessons/3d-basic-rendering/rasterization-practical-implementation/projection-stage)
- [Rasterization: a Practical Implementation (The Rasterization Stage)](https://www.scratchapixel.com/lessons/3d-basic-rendering/rasterization-practical-implementation/rasterization-stage)
- [Rasterization: a Practical Implementation (The Visibility Problem, the Depth Buffer Algorithm and Depth Interpolation)](https://www.scratchapixel.com/lessons/3d-basic-rendering/rasterization-practical-implementation/visibility-problem-depth-buffer-depth-interpolation)
- [Rasterization: a Practical Implementation (Perspective Correct Interpolation and Vertex Attributes)](https://www.scratchapixel.com/lessons/3d-basic-rendering/rasterization-practical-implementation/perspective-correct-interpolation-vertex-attributes)
- [Rasterization: a Practical Implementation (Rasterization: a Practical Implementation)](https://www.scratchapixel.com/lessons/3d-basic-rendering/rasterization-practical-implementation/rasterization-practical-implementation)
- [Rasterization: a Practical Implementation (source code)](https://www.scratchapixel.com/code.php?id=26&origin=/lessons/3d-basic-rendering/rasterization-practical-implementation)
- [Rendering Pipeline Overview - OpenGL Wiki](https://www.khronos.org/opengl/wiki/Rendering_Pipeline_Overview)
- [SI03-graphics pipeline](http://romain.vergne.free.fr/teaching/IS/SI03-pipeline.html)
- [500 Lines or Less | A 3D Modeller](http://aosabook.org/en/500L/a-3d-modeller.html#model-world-view-and-projection-coordinate-spaces)
- [GTA V - Graphics Study - Adrian Courrèges](http://www.adriancourreges.com/blog/2015/11/02/gta-v-graphics-study/)
- [Supreme Commander - Graphics Study - Adrian Courrèges](http://www.adriancourreges.com/blog/2015/06/23/supreme-commander-graphics-study/)
- [Deus Ex: Human Revolution - Graphics Study - Adrian Courrèges](http://www.adriancourreges.com/blog/2015/03/10/deus-ex-human-revolution-graphics-study/)

Tips:

- [Humus - 3D](http://www.humus.name/index.php?page=3D&ID=80) - Interior Mapping. For large city simulation, renders the interior of buildings without requiring additional geometry. See [Ogre Forums • View topic - Interior Mapping](http://www.ogre3d.org/forums/viewtopic.php?t=30275)

Deferred Rendering:

> The motivation for deferred is that we want want to have a lot of lights and in order to achieve that we want to do as few duplicated calculations as possible. In order to do that we delay / defer computing of the lighting as much as possible and limit the calculations only to the area visible withing each light radius

- [Marcin Ignac : Deferred Rendering Explained](http://marcinignac.com/blog/deferred-rendering-explained/) and https://github.com/vorg/pex-exp-deferred-rendering-explained/

### Physically Based Rendering

Aka PBR

- [Physically based rendering — Wikipedia](https://en.wikipedia.org/wiki/Physically_based_rendering)
- [Wolfire - Physically Based Rendering : gamedev](https://www.reddit.com/r/gamedev/comments/3ppmpm/wolfire_physically_based_rendering/)
- Pragmatic physically based rendering
	- [Marcin Ignac : Pragmatic physically based rendering : Intro](http://marcinignac.com/blog/pragmatic-pbr-intro/)
	- [Marcin Ignac : Pragmatic physically based rendering : Setup & Gamma](http://marcinignac.com/blog/pragmatic-pbr-setup-and-gamma/)
	- [Marcin Ignac : Pragmatic physically based rendering : HDR](http://marcinignac.com/blog/pragmatic-pbr-hdr/)
	- http://marcinignac.com/blog/pragmatic-pbr-intro/materials/
	- http://marcinignac.com/blog/pragmatic-pbr-intro/mixing/
	- http://marcinignac.com/blog/pragmatic-pbr-intro/exposure/
	- https://github.com/vorg/pragmatic-pbr
- [Physically Based Rendering: From Theory to Implementation](http://www.pbrt.org/)
- [Basic Theory of Physically-Based Rendering – Marmoset](https://www.marmoset.co/posts/basic-theory-of-physically-based-rendering/)
- [Physically-Based Rendering, And You Can Too! – Marmoset](https://www.marmoset.co/posts/physically-based-rendering-and-you-can-too/)
- [PBR Texture Conversion – Marmoset](https://www.marmoset.co/posts/pbr-texture-conversion/)
- [WebGL Paris 2015 - Outils d'environnement pour le PBR (Physically Based Rendering) - YouTube](https://www.youtube.com/watch?v=xJmEEI7xDmU)
	- [Paris WebGL - PBR envtools](http://cedricpinson.com/ParisWebGL2015/)
	- https://github.com/cedricpinson/envtools/
	- [Physical Based Rendering](http://osgjs.org/examples/pbr/)
	- [Le PBR (Physically Based Rendering) avec WebGL - Cédric Pinson - YouTube](https://www.youtube.com/watch?v=poS6_oVEI4g)
	- [Paris WebGL - prototype of PBR](http://cedricpinson.com/ParisWebGL2014/)
	- [SIGGRAPH 2014: Sketchfab previews Physically Based Rendering on the Web](https://labs.sketchfab.com/siggraph2014/)
- [Physically Based Rendering | PBR Texturing – 3DCoat](http://3dcoat.com/pbr/)
- [Readings on Physically Based Rendering | Interplay of Light](https://interplayoflight.wordpress.com/2013/12/30/readings-on-physically-based-rendering/)
- [Réfractométrie — Wikipédia](https://fr.wikipedia.org/wiki/R%C3%A9fractom%C3%A9trie)
- [PBR shader source](http://orsvarn.com/post/pbr-shader-source/)
- [Advanced WebGL - Part 3: Irradiance Environment Map - Codeflow](http://codeflow.org/entries/2011/apr/18/advanced-webgl-part-3-irradiance-environment-map/)
- [WebGL Deferred Irradiance Volumes - Codeflow](http://codeflow.org/entries/2012/aug/25/webgl-deferred-irradiance-volumes/)
- [Testing](https://emackey.github.io/testing-pbr/) and [emackey/testing-pbr: Various tests of Physically-Based Rendering via Three.js](https://github.com/emackey/testing-pbr)
- [WebGL PBR Implementation « The blog at the bottom of the sea](https://blog.demofox.org/2017/07/10/webgl-pbr-implementation/)

### Tile rendering

- Progressive render: Render low sample to rendering quicker, then complete a the full sample for missing data
- [progressive rendering via tiled backing store · ariya.io](https://ariya.io/2011/06/progressive-rendering-via-tiled-backing-store)

About tiled rendering architectures:

> These two simple tips can speed up your rendering by 40%!
> 
> I mentioned in my notes a couple days ago about Pinball FX2 VR that it wasn’t holding 60 fps. I investigated with Qualcomm’s Snapdragon Profiler and it turns out that it suffers from mobile GPU specific pitfalls that would not be at all obvious to developers coming from a PC or console background.
> 
> Both the Snapdragon Adreno and ARM Mali GPUs found in Gear VR use a tiled rendering architecture. Mali uses small, fixed size tiles, and Adreno uses larger, variable sized “bins”, but the performance characteristics are similar. The idea is that instead of drawing triangles one at a time directly to a color / depth buffer in main memory, the triangles are grouped so that all the triangles in a small are can be drawn at once, using a tiny on-chip color buffer and depth buffer. If things go right, the traffic to main memory is just linear writes of the color buffer, the depth buffer doesn’t ever actually exist in main memory, and both power and performance are saved.
> 
> However, for this to work, you have to do all your drawing to a surface in one batch.
> 
> In the old days of simple rendering techniques, drawing straight to the screen, this happened pretty much automatically. However, many modern techniques involve rendering something to a separate buffer so it can be used as a texture, which can ruin things.
> 
> This is an anti-pattern for mobile graphics:
> 
> Start drawing stuff to your scene.
> Switch to another framebuffer to render some effect.
> Switch back to your scene to use that texture.
> 
> There is another subtle case that can cause inefficiency – if you don’t explicitly clear or invalidate all the render buffers you use, the driver has to be pessimistic and assume that you are expecting whatever you last drew to the buffer to remain there. Some apps would do things like only updating the dirty rectangles in a changing UI instead of rendering it completely, so that case does matter for correctness. Not knowing ahead of time if the drawing is going to cover every pixel, the driver is forced to initialize the internal tile memory by reading the real framebuffer contents from main memory.
> 
> The driver will skip that read if you have done a glClear() that covers the entire buffer. Simple apps often do that, but on most platforms it has become a standard optimization for developers to skip the clear of the color buffer, because every reasonable app does actually cover every pixel with drawing. On mobile, this is a de-optimization! The clear will always be faster than the forced read from main memory. The even-better solution is to use glInvalidateFramebuffer(), which does nothing but tell the driver that it can safely skip the read, even if you don’t clear.
> 
> EDIT: I forgot to mention that you should also do a glInvalidateFramebuffer() on your depth buffer after you have finished rendering, but before flushing. This tells the driver that you promise not to use the depth buffer again, so it doesn't have to write it out to memory along with the color buffer.
> 
> On Adreno, if you are using glInvalidateFramebuffer() and you can noclip outside of your world, the leftover garbage data in the areas where nothing is drawn let you see the actual bin layout on screen. On Mali, invalidates are equivalent to clears.
> 
> A less common historical optimization was to also avoid clearing the depth buffer by halving your depth precision and switching the depth range and test sense each frame. Don’t ever do that nowadays – it will trigger the bad reads on mobile, but it will also screw up the various fast-Z optimizations on desktop GPUs.
> 
> The attached image is a trace view from Snapdragon Profiler from a frame of Pinball FX2 VR.
> 
> The fact that there is a single green IB1 Start Marker and red Flush Marker is a good thing, it means that the CPU didn’t try to read anything back mid-render, so everything proceeded without any stalls, as fast as it can.
> 
> There are a lot of surfaces, which is concerning. Ideally, you just want to see two surfaces, one for each VR eye. What is happening here is that one eye is rendered to a 973 x 973 resolution surface (which is odd – should be 1024 x 1024, there is edge stretching visible), then several small and fast surfaces are rendered, then the second eye is rendered, then several small and fast surfaces for that eye, then the poison part – it goes back to both eye buffer surfaces to use the results of the little texture renderings. This go-back phase is just a single full screen quad, but it is taking a third of the total GPU time!
> 
> The green Binning blocks show the time spent sorting all the triangles into the individual bins. This is largely dominated by the triangle count in the scene and the number of bins, which is a function of buffer options. This looks fine.
> 
> The red GMEM Load bars are all waste due to not clearing / invalidating the framebuffer before rendering, and returning to the partly-rendered framebuffer. *A good mobile app should not have any GMEM Loads at all*.
> 
> The cyan Render bars are where the GPU is running fragment shaders to the internal bin memory. This looks fine.
> 
> The GMEM Store bars are when the GPU writes the bin out to main memory, which is unavoidable, but it happens twice as much here as it should, because the same buffer is returned to twice.
> 
> Invalidating the color buffer is a trivial fix, but the mid-frame rendering is the more important problem, and more difficult to fix.
> 
> Many off screen renders, like shadow buffers, can, with a little effort, be done before the eye buffers are rendered (and shared between the two eyes!), rather than on-demand, midway through the eye buffers. Drivers can sometimes figure this out and do it automatically, but it is better to not rely on that, and structure your code properly.
> 
> Unfortunately, the internal rendering here is for a glow / glare effect, and it is using the “bright” pixels that were just rendered, so it isn’t obvious how to have it ready before the eyes are drawn.
> 
> What to do?
> 
> Option 1:
> Don’t do the glare effect at all. Often the simplest solutions are best. It is easy to get a little bit over attached to some effects, and not judge them by their true value. Right now, this effect is costing a LOT. Skipping the glare means you don’t need to do the other surface renders, and you wind up with just the standard two surfaces being rendered.
> 
> Option 2:
> Do the glare mip mapping before the eye buffer rendering, but use the previous frame’s eye buffer as the source, since it is already done. That wouldn’t be in exactly the right place if your head is turning, so the glare would swim around a little bit. That might be OK, but you could mostly correct for it by reprojecting the texture based on the view change, TimeWarp / temporal anti-aliasing style. Getting that right can be pretty tricky. It would not be the exact same effect, since the glare would be coming from an eye buffer with glare already applied. That might be pleasing, but it might also be a runaway feedback loop, depending on parameters.
> 
> Option 3:
> Instead of copying the results of the main eye buffer rendering to the glare buffer, actually render the geometry again to that smaller buffer. Rendering everything would be bad, but if the “bright” surfaces that could contribute to the glare are a small subset of the entire scene, this can work out. There may be some artifacts due to bright objects not being occluded by surfaces that weren’t drawn.
> 
> ![Trace view from Snapdragon Profiler from a frame of Pinball FX2 VR](Pinball%20FX2%20VR%20render%20frame.jpg)
— [John Carmack - These two simple tips can speed up your rendering...](https://www.facebook.com/permalink.php?story_fbid=1923486231219218&id=100006735798590)

## Primite

Aka object, model, mesh, draw geometry. Vertexes and normals

2D:

- [gen/Shape - Spark project](http://www.libspark.org/wiki/gen/Shape) - Util for primitive shape drawing. Square, fan, octagon, corner round square, etc. see http://snippets.libspark.org/svn/as2/Emzah/src/com/emzah/display/Shape.as
- `drawDonut.as` and `GraphicsUtils.as`
- [doesnotcompute » GraphicsUtil. A Utility Class for Drawing Arrows](http://www.dncompute.com/blog/2008/07/17/graphicsutil-a-utility-class-for-drawing-arrows.html) - Draw arrow head

3D:

- [Inigo Quilez :: fractals, computer graphics, mathematics, demoscene and more](http://www.iquilezles.org/www/articles/normals/normals.htm) - clever normalization of a mesh
- [Inigo Quilez :: fractals, computer graphics, mathematics, demoscene and more](http://www.iquilezles.org/www/articles/3dmodels/3dmodels.htm) - introduction to 3d models generation
- [Inigo Quilez :: fractals, computer graphics, mathematics, demoscene and more](http://www.iquilezles.org/www/articles/distfunctions/distfunctions.htm) - modeling with distance functions
- [Inigo Quilez :: fractals, computer graphics, mathematics, demoscene and more](http://www.iquilezles.org/www/articles/patchedsphere/patchedsphere.htm) - patched sphere, making good polygonal spheres
- [Inigo Quilez :: fractals, computer graphics, mathematics, demoscene and more](http://www.iquilezles.org/www/articles/smin/smin.htm) - smooth minimum

## Depth sorting

Aka z-sorting, depth buffer

See [Depth sorting](Projection#Depth sorting)

- [order-independent transparency](https://tsherif.github.io/nanogl.js/examples/oit.html) - WebGL. Based on [Weighted Blended Order-Independent Transparency](http://jcgt.org/published/0002/02/09/)
- [Inigo Quilez :: fractals, computer graphics, mathematics, demoscene and more](http://www.iquilezles.org/www/articles/volumesort/volumesort.htm) - volumetric sort

## Ray tracing

Aka path tracing, ray marching, raytracing, pathtracing

- [Volume ray casting — Wikipedia](https://en.wikipedia.org/wiki/Volume_ray_casting)
- [Ray tracing vs Path tracing, in plain English | LAGOA](http://home.lagoa.com/2014/04/ray-tracing-vs-path-tracing-in-plain-english/)
- [Ray tracing (graphics) — Wikipedia](https://en.wikipedia.org/wiki/Ray_tracing_%28graphics%29)
- [Introduction to Ray Tracing: a Simple Method for Creating 3D Images (How Does It Work?)](http://www.scratchapixel.com/lessons/3d-basic-rendering/introduction-to-ray-tracing)
- [Breakdown of a Simple Ray Tracer with WebGL by Ken Perlin](http://mrl.nyu.edu/~perlin/raytrace1_breakdown/) - see also [Breakdown of a Simple Ray Tracer | Hacker News](https://news.ycombinator.com/item?id=13563577)
- [Inigo Quilez :: fractals, computer graphics, mathematics, demoscene and more](http://www.iquilezles.org/www/articles/simplegpurt/simplegpurt.htm) - simple gpu raytracing
- [Inigo Quilez :: fractals, computer graphics, mathematics, demoscene and more](http://www.iquilezles.org/www/articles/simplepathtracing/simplepathtracing.htm) - simple pathtracing
- [Inigo Quilez :: fractals, computer graphics, mathematics, demoscene and more](http://www.iquilezles.org/www/articles/rtintro/rtintro.htm) - introduction to raytracing
- [Inigo Quilez :: fractals, computer graphics, mathematics, demoscene and more](http://www.iquilezles.org/www/articles/raytracing/raytracing.htm) - modern raytracing
- [Inigo Quilez :: fractals, computer graphics, mathematics, demoscene and more](http://www.iquilezles.org/www/articles/filteringrm/filteringrm.htm) - texturing and raymarching
- [Inigo Quilez :: fractals, computer graphics, mathematics, demoscene and more](http://www.iquilezles.org/www/articles/raypolys/raypolys.htm) - rays and polygons
- [Inigo Quilez :: fractals, computer graphics, mathematics, demoscene and more](http://www.iquilezles.org/www/articles/terrainmarching/terrainmarching.htm) - terrain raymarching
- [CPU Real Time Rendering - Report](http://graphics.cs.williams.edu/courses/cs371/f16/gallery/4-midterm/realtime/report.md.html)
- [Premiers pas, Raytracer en C++ : LeGreg Homepage - Gregory Massal](http://www.massal.net/article/raytrace/page1.html)
- [erichlof/THREE.js-PathTracing-Renderer: Real-time PathTracing with global illumination and progressive rendering, all on top of the Three.js WebGL framework. Click here for Live Demo: https://erichlof.github.io/THREE.js-PathTracing-Renderer/ThreeJS_PathTracing_Renderer_GeometryShowcase.html](https://github.com/erichlof/THREE.js-PathTracing-Renderer)

## Ray casting

- [Blobs in Games: 2d Visibility](http://simblob.blogspot.fr/2012/07/2d-visibility.html)
- [2d Visibility](http://www.redblobgames.com/articles/visibility/)
- [Ray casting — Wikipedia](https://en.wikipedia.org/wiki/Ray_casting)
- [Raycasting](http://lodev.org/cgtutor/raycasting.html)

## Voxel

- [Let's Make a Voxel Engine](https://sites.google.com/site/letsmakeavoxelengine/)
- [Voxel — Wikipedia](https://en.wikipedia.org/wiki/Voxel)
- [Voxel Edges](https://www.shadertoy.com/view/4dfGzs)
- [Inigo Quilez :: fractals, computer graphics, mathematics, demoscene and more](http://www.iquilezles.org/www/articles/voxel/voxel.htm) - simple voxel
- [Inigo Quilez :: fractals, computer graphics, mathematics, demoscene and more](http://www.iquilezles.org/www/articles/voxellines/voxellines.htm) - voxel lines and occlusion
- [Voxel](http://leon196.github.io/Octree/prototype/index.html) - Voxel octree WebGL demo with local level of detail by Leon Denise. See https://github.com/leon196/Voxel
- [GigaVoxels + Sparse Textures](https://github.com/lilleyse/Sparse-Texture-Voxels) - see [Real-Time Voxels](http://realtimevoxels.blogspot.fr/)
- [High Resolution Sparse Voxel DAGs - HighResolutionSparseVoxelDAGs.pdf](http://www.cse.chalmers.se/~uffe/HighResolutionSparseVoxelDAGs.pdf)

## Draw a line

- [Bresenham's line algorithm — Wikipedia](https://en.wikipedia.org/wiki/Bresenham%27s_line_algorithm#The_algorithm)
- [Xiaolin Wu's line algorithm — Wikipedia](https://en.wikipedia.org/wiki/Xiaolin_Wu%27s_line_algorithm)

## Motion effect

Aka movement interpolation, animation smears, smears frames

For wheels use spiral blur / radial blur cage: you can mix/swap between a plan with 2D pre-blured texture (or a dedicated 3D model) and the base 3D model and change opacity, or instantiate multiple time the same mesh

See also "wagon wheel effect"

Use a vertex shader to compute motion (velocity texture). [Motion blur](Blur#Motion blur) shader can be used too

	using UnityEngine;
	
	[ExecuteInEditMode]
	public class DynamicScale : MonoBehaviour
	{
		Vector3 lastPosition;
		
		void Start()
		{
			lastPosition = transform.position;
		}
		
		void LateUpdate()
		{
			Vector3 delta = transform.position - lastPosition;
			transform.localRotation = Quaternion.LookRotation(delta + Vector3.forward * 0.001f);
			float l = 1f + delta.magnitude;
			float wh = Mathf.Sqrt(1f / l);
			transform.localScale = new Vector3(wh, wh, l);
			
			lastPosition = transform.position;
		}
	}

For cube:

	volume of a cube; V=h×w×L
	you know h=w though and assume volume is 1, so:
	1=w×w×L
	1=w²×L
	1/L=w²
	√(1/L)=w

For general case (volumes other than 1):

	w_new = w_old*√(L_old/L_new)

> You can move wheel rotation to vertex shader, instead of doing it as an object. That adds certain difficulties, such as complications with normal maps and added shader costs, however it also opens you a way to precisely control how much rotational blur you get independently from rotation speed using previous frame switch.
> — [Wheels, motion blur and motion vector - Unreal Engine Forums](https://forums.unrealengine.com/development-discussion/rendering/121459-wheels-motion-blur-and-motion-vectors/page2)

> simulating motion blur of fast-moving objects using multi-pass rendering. In the first pass, the fast-moving geometry is rendered unblurred into a framebuffer object. In the second pass, a special vertex shader stretches the geometry between the previous and current vertex position based on the normal at the vertex and apparent shutter duration (stretch length), and the fragment shader applies supersampling to the first pass results to generate a blurred visual.
> — [Motion Blur ES2 Sample](https://docs.nvidia.com/gameworks/content/gameworkslibrary/graphicssamples/opengl_samples/motionblures2sample.htm)

> This sample shows a filtering method for simulating motion blur of fast-moving objects. The method used is a 2D full-screen post-process that works on a normal framebuffer augmented with a screen-space velocity buffer; thus, filtering performance is not dependent on scene geometric complexity.
> — [Motion Blur GL4/GLES3 Advanced Sample](https://docs.nvidia.com/gameworks/content/gameworkslibrary/graphicssamples/opengl_samples/motionblurgl4gles3advancedsample.htm)

> per-object motion blur

> We conclude that motion blur effects, while useful for reducing artifacts and achieving a realistic ‘look’, do not significantly enhance the player experience.
> – [farpeek - Simulated Motion Blur doe not improve player experience in Racing Game in Proceeding of Motion in Games](http://farpeek.com/index.php/pubs/9-mstudy) by Lavanya Sharan, Neo Zhe Han, Kenny Mitchell, Jessica Hodgins

- [The Illusion of Motion – The Sea of Ideas](https://paulbakaus.com/tutorials/performance/the-illusion-of-motion/)
- [CodePen - 3D motion smear](http://codepen.io/zadvorsky/full/NAgGZX/) [3d-motion-smear.zip](3d-motion-smear.zip)
- [THREE.JS Buffer Animation System](https://github.com/zadvorsky/three.bas)
- [pikopik on Twitter: "I made it look more mathy than it is, its really simple! code if you can't figure it out: https://t.co/EvuZEZLvF7 #unitytips I guess https://t.co/yHCK8hDxQj"](https://twitter.com/_pikopik/status/882346033656844288)
- [LuggLD/SmearFrame: Unreal Engine 4 smear frame material effect](https://github.com/LuggLD/SmearFrame)
- [Cartridge Game on Twitter: "The game seem to use smear frame (?) which i actually pretty good. Really fluid and cartoon-y animation. Not very common… https://t.co/Ibjn8j6Pr1"](https://twitter.com/cartridgegames/status/874391704484413440)
- [terminology - What i "radial blur"? - Arqade](https://gaming.stackexchange.com/questions/306721/what-is-radial-blur) - motion blur for rotation objects
- [keijiro/KinoMotion: Motion blur post-processing effect for Unity](https://github.com/keijiro/KinoMotion)
- [Radial Blur Shader - Texture - Unity Forum](https://forum.unity.com/threads/radial-blur-shader-texture.406804/)
- [Radial Blur Shader «  Unity Coding – Unity3D](http://unitycoder.com/blog/2012/10/06/radial-blur-shader/)
- [UFO Test: Multiple Framerates](https://www.testufo.com/)
- [About Thi Site | Blur Busters](https://www.blurbusters.com/about/site/)
- [GPU Gem | NVIDIA Developer](https://developer.nvidia.com/gpugems/GPUGems3/gpugems3_ch27.html)
- [john-chapman-graphics: Per-Object Motion Blur](http://john-chapman-graphics.blogspot.com/2013/01/per-object-motion-blur.html)
- [A Reconstruction Filter for Plausible Motion Blur](http://casual-effects.com/research/McGuire2012Blur/index.html) - "Plausible Motion Blur"
- [Unity - Manual:  Motion Blur](https://docs.unity3d.com/Manual/PostProcessing-MotionBlur.html) - Unity Standard Assets Motion Blur
- [Unity - Manual: Camera Motion Blur](https://docs.unity3d.com/550/Documentation/Manual/script-CameraMotionBlur.html) - Unity Standard Assets Camera Motion Blur (removed in Unity 5.6)
- [3d Max Help: Object Motion Blur](http://docs.autodesk.com/3DSMAX/15/ENU/3ds-Max-Help/index.html?url=files/GUID-22748E7B-6C68-4437-922D-AF2309855C8A.htm,topicNumber=d30e607691)
- [3d Max Help: Image Motion Blur](http://docs.autodesk.com/3DSMAX/15/ENU/3ds-Max-Help/index.html?url=files/GUID-CDD7A087-F914-4B53-8DFC-1E406F8DC881.htm,topicNumber=d30e604841)
- [3d Max Help: Scene Motion Blur](http://docs.autodesk.com/3DSMAX/15/ENU/3ds-Max-Help/index.html?url=files/GUID-65BE9F44-FB64-4282-B7AB-BC26C31115A6.htm,topicNumber=d30e610199)
- [keijiro/KinoVision: Frame visualization utility for Unity](https://github.com/keijiro/KinoVision)
- [[WIP] Spinning Wheel Effect - Unity Forum](https://forum.unity.com/threads/wip-spinning-wheel-effect.413186/)

## Raymarching Distance Fields

Infinite effect, use raymarcher

- [Raymarching Distance Fields](http://lightbits.github.io/toys/raymarching/raymarching.html)
- [9bit Science: Raymarching Distance Fields](http://9bitscience.blogspot.fr/2013/07/raymarching-distance-fields_14.html)
- [Infinite cubes | Coding on acid.](https://makc3d.wordpress.com/2015/08/14/infinite-cubes/)
- https://github.com/lightbits/ray-march
- [Relativistic lattice | Coding on acid.](https://makc3d.wordpress.com/2015/08/18/relativistic-lattice/)
- [GLSL Sandbox](http://glslsandbox.com/e#20300.0)

## Vertex Shader

- [APEXvj – the new epoch « simppa.fi/blog](http://www.simppa.fi/blog/apexvj_the_new_epoch/) - Some optimizations tips (For Flash Stage3D, but should works for other 3D platforms). See "Mobile AIR Performance"
- [Fluffy predator with THREE.js & instanced geometry – Youpi !](http://barradeau.com/blog/?p=1109) - [nicoptere/FluffyPredator: Fluffy Predator with THREE.js & instanced geometry](https://github.com/nicoptere/FluffyPredator/)
- [Into Vertex Shaders – Szenia Zadvornykh – Medium](https://medium.com/@Zadvorsky/into-vertex-shaders-594e6d8cd804)
- [Quick Game Art Tips - Interactive Grass Shader | Minions Art on Patreon](https://www.patreon.com/posts/quick-game-art-19844414) - See ![Interactive Grass Shader](Vertex%20shader/Grass%20Shader/Interactive%20Grass%20Shader.gif)
- [Quick Game Art Tips - Unity Moving Grass | Minions Art on Patreon](https://www.patreon.com/posts/quick-game-art-13724221) - See ![Unity Moving Grass](Vertex%20shader/Grass%20Shader/Unity%20Moving%20Grass.gif)

## Pixel Shader

See also [color space](Color space) (HSL, ColorMatrix)

Aka Fragment Shaders

- [Articles | Nutty Software](http://wayback.archive.org/web/20130721064929/http://www.nutty.ca/?cat=11)
- [Shaders](http://loopspace.mathforge.org/HowDidIDoThat/Codea/Shaders/)
- [Shader — Wikipedia](https://en.wikipedia.org/wiki/Shader)
- [The Book of Shaders](http://thebookofshaders.com/)
- [alphablending - How to use pre-multiplied during image convolution to solve alpha bleed problem? - Stack Overflow](https://stackoverflow.com/questions/4854839/how-to-use-pre-multiplied-during-image-convolution-to-solve-alpha-bleed-problem)

Usefull functions:

- [Easing](Animation#Easing)

### Pixel shaders examples and libraries

- [Minions Art is creating Game Art Tips and Astro Kat, a Catventure game! | Patreon](https://www.patreon.com/minionsart) - A collection of sharers, examples, tips, etc.
- [Shadertoys](http://evasion.imag.fr/~Fabrice.Neyret/demos/Shadertoy/indexImages.html)
- [Poetic Computational Sunset by Baku Hashimoto](http://player.thebookofshaders.com/?log=161116214458)
- [Various image filters (contrast adjustment, tilt-shift, lens defocus, etc.) using WebGL](https://github.com/evanw/webgl-filter/)
- Some fancy shaders [Fifty shaders of grey | iq12 - Publishing games and stuff since mayans failed us](http://wayback.archive.org/web/20160120003645/http://iq12.com/2013/04/fifty-shaders-of-grey/)
- [Index of /](http://wayback.archive.org/web/20170131145057/http://www.cake23.de/) and https://github.com/Flexi23/Cake23/tree/master/Cake23/WebTemplates
- [Unity Cinematic Image Effects](https://bitbucket.org/Unity-Technologies/cinematic-image-effects)
- [Procedural soap bubble](http://mrl.nyu.edu/~perlin/bubble_breakdown/)
- [Realistic water shader for Three.js](https://github.com/jbouny/ocean)
- [GLSL Sandbox Gallery](http://glslsandbox.com/)
- [CodePen - GLSL: Chrome](https://codepen.io/shubniggurath/full/dmoWKp)
- [Return of the ripples! Shallow water simulation with Pixel Bender. | Der Schmale - David Lenaerts's blog](http://www.derschmale.com/2009/04/23/return-of-the-ripples-shallow-water-simulation-with-pixel-bender/)
- [Pixel Bender Filters and Algorithms | Professional Papervision3D Book](https://professionalpapervision.wordpress.com/2009/03/18/pixel-bender-filters-and-alogorithms/)
- Collection of filters, etc. written in C (Generic Graphics Library) [GEGL Operation Reference](http://codecave.org/operations.html#GEGL%20operations) see `/operations/common/*`
- Few filters written in LUA for GIMP [Image Processing with gluas](http://pippin.gimp.org/image-processing/image_processing.html)
- https://github.com/devon-o/Starling-Filters and https://github.com/shin10/Starling-Filters - A collection of filters for use with the Starling AS3 framework
- [Filmic Tonemapping Operators – Site Title](http://filmicworlds.com/blog/filmic-tonemapping-operators/)
- [Inigo Quilez :: fractals, computer graphics, mathematics, demoscene and more](http://www.iquilezles.org/www/articles/deform/deform.htm) - plane deformations
- [Inigo Quilez :: fractals, computer graphics, mathematics, demoscene and more](http://www.iquilezles.org/www/articles/tunnel/tunnel.htm) - tunnel artifact
- [Chapter 4. Point operations](http://pippin.gimp.org/image-processing/chap_point.html) - Threshold, brightness, contrast, invert, gamma, levels, etc.
- [glfx.js](http://evanw.github.io/glfx.js/demo/) - An image effects library for JavaScript using WebGL (Brightness / Contrast, Hue / Saturation, Vibrance, Denoise, Unsharp Mask, Noise, Sepia, Vignette, Zoom Blur, Triangle Blur, Tilt Shift, Lens Blur, Swirl, Bulge / Pinch, Perspective, Ink, Edge Work, Hexagonal Pixelate, Dot Screen, Color Halftone). See https://github.com/evanw/glfx.js (and [WebGL Filter](http://evanw.github.io/webgl-filter/), https://github.com/evanw/webgl-filter/)
- [A collection of post-processing shaders written for ReShade](https://github.com/crosire/reshade-shaders)
- [forked: Dreadus shotgun, dissolve shader version - js do it](http://jsrun.it/makc/zKOSH) - Dissolve shader (grayscale noise texture + custom shader material)
- [Walls](http://samsy.ninja/nebula/index.html)
- [Quick Game Art Tips - Unity Triplanar Terrain Shader | Minions Art on Patreon](https://www.patreon.com/posts/quick-game-art-16714688) - A collection of shared effects
- [Standard Assets - Asset Store](https://assetstore.unity.com/packages/essentials/asset-packs/standard-assets-32351) - Unity Standard Assets (see Effects) [Unity - Manual: Standard Assets](https://docs.unity3d.com/540/Documentation/Manual/HOWTO-InstallStandardAssets.html)
	
		Shader "Toon/Lit TriPlanar" {
			Properties{
				_Color("Main Color", Color) = (0.5,0.5,0.5,1)
				_MainTex("Top Texture", 2D) = "white" {}
				_MainTexSide("Side/Bottom Texture", 2D) = "white" {}
				_Ramp("Toon Ramp (RGB)", 2D) = "gray" {}
				_Normal("Normal/Noise", 2D) = "bump" {}
				_Scale("Top Scale", Range(-2,2)) = 1
				_SideScale("Side Scale", Range(-2,2)) = 1
				_NoiseScale("Noise Scale", Range(-2,2)) = 1
				_TopSpread("TopSpread", Range(-2,2)) = 1
				_EdgeWidth("EdgeWidth", Range(0,0.5)) = 1
				_RimPower("Rim Power", Range(-2,20)) = 1
				_RimColor("Rim Color Top", Color) = (0.5,0.5,0.5,1)
				_RimColor2("Rim Color Side/Bottom", Color) = (0.5,0.5,0.5,1)
			}
		
				SubShader{
				Tags{ "RenderType" = "Opaque" }
				LOD 200
		
				CGPROGRAM
		#pragma surface surf ToonRamp
		
				sampler2D _Ramp;
		
			// custom lighting function that uses a texture ramp based
			// on angle between light direction and normal
		#pragma lighting ToonRamp exclude_path:prepass
			inline half4 LightingToonRamp(SurfaceOutput s, half3 lightDir, half atten)
			{
		#ifndef USING_DIRECTIONAL_LIGHT
				lightDir = normalize(lightDir);
		#endif
		
				half d = dot(s.Normal, lightDir)*0.5 + 0.5;
				half3 ramp = tex2D(_Ramp, float2(d,d)).rgb;
		
				half4 c;
				c.rgb = s.Albedo * _LightColor0.rgb * ramp * (atten * 2);
				c.a = 0;
				return c;
			}
		
		
			sampler2D _MainTex, _MainTexSide, _Normal;
			float4 _Color, _RimColor, _RimColor2;
			float _RimPower;
			float  _TopSpread, _EdgeWidth;
			float _Scale, _SideScale, _NoiseScale;
		
			struct Input {
				float2 uv_MainTex : TEXCOORD0;
				float3 worldPos; // world position built-in value
				float3 worldNormal; // world normal built-in value
				float3 viewDir;// view direction built-in value we're using for rimlight
			};
		
			void surf(Input IN, inout SurfaceOutput o) {
		
				// clamp (saturate) and increase(pow) the worldnormal value to use as a blend between the projected textures
				float3 blendNormal = saturate(pow(IN.worldNormal * 1.4,4));
		
				// normal noise triplanar for x, y, z sides
				float3 xn = tex2D(_Normal, IN.worldPos.zy * _NoiseScale);
				float3 yn = tex2D(_Normal, IN.worldPos.zx * _NoiseScale);
				float3 zn = tex2D(_Normal, IN.worldPos.xy * _NoiseScale);
		
				// lerped together all sides for noise texture
				float3 noisetexture = zn;
				noisetexture = lerp(noisetexture, xn, blendNormal.x);
				noisetexture = lerp(noisetexture, yn, blendNormal.y);
		
				// triplanar for top texture for x, y, z sides
				float3 xm = tex2D(_MainTex, IN.worldPos.zy * _Scale);
				float3 zm = tex2D(_MainTex, IN.worldPos.xy * _Scale);
				float3 ym = tex2D(_MainTex, IN.worldPos.zx * _Scale);
		
				// lerped together all sides for top texture
				float3 toptexture = zm;
				toptexture = lerp(toptexture, xm, blendNormal.x);
				toptexture = lerp(toptexture, ym, blendNormal.y);
		
				// triplanar for side and bottom texture, x,y,z sides
				float3 x = tex2D(_MainTexSide, IN.worldPos.zy * _SideScale);
				float3 y = tex2D(_MainTexSide, IN.worldPos.zx * _SideScale);
				float3 z = tex2D(_MainTexSide, IN.worldPos.xy * _SideScale);
		
				// lerped together all sides for side bottom texture
				float3 sidetexture = z;
				sidetexture = lerp(sidetexture, x, blendNormal.x);
				sidetexture = lerp(sidetexture, y, blendNormal.y);
		
				// rim light for fuzzy top texture
				half rim = 1.0 - saturate(dot(normalize(IN.viewDir), o.Normal * noisetexture));
		
				// rim light for side/bottom texture
				half rim2 = 1.0 - saturate(dot(normalize(IN.viewDir), o.Normal));
		
				// dot product of world normal and surface normal + noise
				float worldNormalDotNoise = dot(o.Normal + (noisetexture.y + (noisetexture * 0.5)), IN.worldNormal.y);
		
				// if dot product is higher than the top spread slider, multiplied by triplanar mapped top texture
				// step is replacing an if statement to avoid branching :
				// if (worldNormalDotNoise > _TopSpread{ o.Albedo = toptexture}
				float3 topTextureResult = step(_TopSpread, worldNormalDotNoise) * toptexture;
		
				// if dot product is lower than the top spread slider, multiplied by triplanar mapped side/bottom texture
				float3 sideTextureResult = step(worldNormalDotNoise, _TopSpread) * sidetexture;
		
				// if dot product is in between the two, make the texture darker
				float3 topTextureEdgeResult = step(_TopSpread, worldNormalDotNoise) * step(worldNormalDotNoise, _TopSpread + _EdgeWidth) *  -0.15;
		
				// final albedo color
				o.Albedo = topTextureResult + sideTextureResult + topTextureEdgeResult;
				o.Albedo *= _Color;
				// adding the fuzzy rimlight(rim) on the top texture, and the harder rimlight (rim2) on the side/bottom texture
				o.Emission = step(_TopSpread, worldNormalDotNoise) * _RimColor.rgb * pow(rim, _RimPower) + step(worldNormalDotNoise, _TopSpread) * _RimColor2.rgb * pow(rim2, _RimPower);
		
		
			}
			ENDCG
		
			}
		
				Fallback "Diffuse"
		}

### Gamma correction

> The issue is that the human eye is adaptive so you get banding on elongated gradients in 8bit/channel precision unless you throw a lot of high-contrast stuff on the screen.
> Gamma-corrected colorspace reallocates the 8bit/channel precision to where it really matters, so it helps with the original problem somewhat, but even with nonlinear gamma 8 bits/channel are just not enough.
> Unfortunately, gamma correction introduces its own set of problems for gradients with saturated colors: 

Doing the math linearly and applying the nonlinearity at end is called [gamma correction](https://en.wikipedia.org/wiki/Gamma_correction) (enhance dark details).

- [Understanding Gamma Correction](http://www.cambridgeincolour.com/tutorials/gamma-correction.htm)
- [RenderWonk » Blog Archive » Adventures with Gamma-Correct Rendering](http://renderwonk.com/blog/index.php/archive/adventures-with-gamma-correct-rendering/)
- search this document for "gamma"
- [Correct color interpolation](Resample#Correct color interpolation)
- [Computer Color is Broken - YouTube](https://www.youtube.com/watch?v=LKnqECcg6Gw)
- [Linear gamma RGB: blur, normal blend](http://ninedegreesbelow.com/photography/linear-gamma-blur-normal-blend.html)
- [Unity - Manual: Linear rendering overview](https://docs.unity3d.com/Manual/LinearLighting.html)
- [Linear Rendering Support with WebGL 2.0 – Unity Blog](https://blogs.unity3d.com/2017/07/17/linear-rendering-support-with-webgl-2-0/)
- [Color: From Hexcodes to Eyeballs](http://jamie-wong.com/post/color/#gamma-correction)

### Palette

- [DIY-Thermocam/ColorSchemes.h at fcede6bcf673b1cf1d4db585eca456e347ab87fe · maxritter/DIY-Thermocam](https://github.com/maxritter/DIY-Thermocam/blob/fcede6bcf673b1cf1d4db585eca456e347ab87fe/Firmware/Source/General/ColorSchemes.h) - RGB Palettes for grayscale (aka Thermal color). 3 colors uint8 values in row, but some contains less colors: `r = colorMap[round(grey * (colorMap.length / 3 - 1) / 255) * 3]`

### Tone map

	/*----------------------------------------- ToneMapFilmic_Hejl2015 ---
	 |  Function ToneMapFilmic_Hejl2015
	 |
	 |  Purpose: This function applies a "film-like" tonemap to supplied
	 |		   HDR pixel. This curve does not approximate gamma2.2,
	 |		   so an explicit sRGB transform should be performed
	 |		  before display.
	 |
	 |  Parameters:
	 |	  float3 hdr (IN)	-- HDR pixel in linear space
	 |	  float  whitePt (IN) -- Scene white point. Must be > 0.0
	 |
	 |  Returns:  Tonemapped pixel, white point corrected, in gamma 1.0 space
	 |
	 |   08-18-15   v1   Jim Hejl
	 *-------------------------------------------------------------------*/
	float3 ToneMapFilmic_Hejl2015(float3 hdr, float whitePt)
	{
	   float4 vh = float4(hdr,whitePt);	// pack: [r,g,b,w]
	   float4 va = (1.425 * vh) + 0.05f;   // eval filmic curve
	   float4 vf = ((vh * va + 0.004f) / ((vh * (va + 0.55f) + 0.0491f))) - 0.0821f;
	   return vf.rgb / vf.www;		  // white point correction
	}

- [Tone mapping — Wikipedia](https://en.wikipedia.org/wiki/Tone_mapping)
- [tonemap: hejl2015](https://www.shadertoy.com/view/llsSD2)
- [Jim Hejl on Twitter: "I'm dropping a new filmic tonemap. Note embedded white point correction & no sRGB approx. Share and enjoy- http://t.co/VOClq0tm7g"](https://twitter.com/jimhejl/status/633777619998130176)
- [Jim Hejl on Twitter: "For linear out, please use this approximation. It doesn't do the gamma2.2 approx in the curve. And it does white point correction for ya! 👍 https://t.co/zQPyPMyGXW"](https://twitter.com/jimhejl/status/841149752389558272/photo/1)

### 360 projection

In a cube

	// vertex
	varying vec3 worldPosition;
	void main () {\n\
		vec4 p = vec4 (position, 1.0);
		worldPosition = (modelMatrix * p).xyz;
		gl_Position = projectionMatrix * modelViewMatrix * p;
	}

	// fragment
	uniform sampler2D map;
	uniform vec3 placement;
	varying vec3 worldPosition;
	const float seamWidth = 0.01;
	
	void main () {
		vec3 R = worldPosition - placement;
		float r = length (R);
		float c = -R.y / r;
		float theta = acos (c);
		float phi = atan (R.x, -R.z);
		float seam = 
			// thin circle around x axis
			max (0.0, 1.0 - abs (R.x / r) / seamWidth) *
			// keep the part facing positive z direction
			clamp (1.0 + (R.z / r) / seamWidth, 0.0, 1.0);
		gl_FragColor = texture2D (map, vec2 (
			0.5 + phi / 6.2831852,
			theta / 3.1415926
		), -2.0 * log2(1.0 + c * c) -12.3 * seam);
	}

- [Sampling equirectangular textures | Coding on acid.](https://makc3d.wordpress.com/2017/01/19/sampling-equirectangular-textures/)
- [Edit fiddle - JSFiddle](http://jsfiddle.net/hfj7gm6t/2879/)

### Arc-tangent

See [Math](Math#Arc-tangent)

> HLSL atan2(x,y) == GLSL atan(y,x)
> GLSL provides two atan-operators. One taking 1 parameter and one taking 2 parameters. The one with 2 parameters is the equivalent of atan2.

- [atan - OpenGL 4 Reference Pages](https://www.khronos.org/registry/OpenGL-Refpages/gl4/html/atan.xhtml)
 
	// AGAL atan2 implementation
	float atan2(float4 v0){
		const float4 fc0 = float4(0, 0, 3.141592654, 2 * 3.141592654);/* Math.PI, 2 * Math.PI */
		const float4 fc1 = float4(0.000000001, 0.7853981634, 0.1821, 0.9675);/* atan2 magic numbers: 2.220446049250313e-16, 0.7853981634, 0.1821, 0.9675 */
		float4 ft0 = v0;
		float4 ft2;
		float4 ft3;
		
		ft0.zw = ft0.zw - ft0.zw;
		/* In their eternal wisdom Adobe or whoever is responsible
		 * made no atan2 in AGAL, so we need to use approximation,
		 * for example the one by Eugene Zatepyakin, Joa Ebert and
		 * Patrick Le Clec'h http://wonderfl.net/c/1HbR/read */
		ft2 = abs(ft0);/* ft2 = |x|, |y| */ +
		/* sge, because dated AGALMiniAssembler does not have seq */
		ft2 = sge(ft0, ft2);/* ft2.zw are both =1 now, since ft0.zw were =0 */
		ft2.xyw = ft2.xyw + ft2.xyw;
		ft2.xy = ft2.xy - ft2.zz;/* ft2 = sgn(x), sgn(y), 1, 2 */
		ft2.w = ft2.w - ft2.x;/* ft2.w = "(partSignX + 1.0)" = 2 - sgn(x) */
		ft2.w = ft2.w * fc1.y;/* ft2.w = "(partSignX + 1.0) * 0.7853981634" */
		ft2.z = ft2.y * ft0.y;/* ft2.z = "y * sign" */
		ft2.z = ft2.z + fc1.x;/* ft2.z = "y * sign + 2.220446049250313e-16" or "absYandR" initial value */
		ft3.x = ft2.x * ft2.z;/* ft3.x = "signX * absYandR" */
		ft3.x = ft0.x - ft3.x;/* ft3.x = "(x - signX * absYandR)" */
		ft3.y = ft2.x * ft0.x;/* ft3.y = "signX * x" */
		ft3.y = ft3.y + ft2.z;/* ft3.y = "(signX * x + absYandR)" */
		ft2.z = ft3.x / ft3.y;/* ft2.z = "(x - signX * absYandR) / (signX * x + absYandR)" or "absYandR" final value */
		ft3.x = ft2.z * ft2.z;/* ft3.x = "absYandR * absYandR" */
		ft3.x = ft3.x * fc1.z;/* ft3.x = "0.1821 * absYandR * absYandR" */
		ft3.x = ft3.x - fc1.w;/* ft3.x = "(0.1821 * absYandR * absYandR - 0.9675)" */
		ft3.x = ft3.x * ft2.z;/* ft3.x = "(0.1821 * absYandR * absYandR - 0.9675) * absYandR" */
		ft3.x = ft3.x + ft2.w;/* ft3.x = "(partSignX + 1.0) * 0.7853981634 + (0.1821 * absYandR * absYandR - 0.9675) * absYandR" */
		ft3.x = ft3.x * ft2.y;/* ft3.x = "((partSignX + 1.0) * 0.7853981634 + (0.1821 * absYandR * absYandR - 0.9675) * absYandR) * sign" */
		return ft3.x;
	}

### Blur

- [Blur](Blur)

### Noise

- [Noise](Noise)

### Thresold

Aka image enhancement (scan)

- [Adaptive Thresholding using Integral Image \[source\] | astatic notes](http://wayback.archive.org/web/20121223171256/http://blog.inspirit.ru/?p=322#more-322)

### Glow

- [(WebGL) Animated selective glow in Three.js - Blog - (BKcore) Thibaut Despoulain](http://bkcore.com/blog/3d/webgl-three-js-animated-selective-glow.html)
- [CodePen - Thank You.](https://codepen.io/shubniggurath/full/GGXKJe/)

### Specular

- [Quick Game Art Tips - Toon Metal | Minions Art on Patreon](https://www.patreon.com/posts/quick-game-art-21398935) - Specular Toon Metal. See ![Toonmetal Tip](Pixel%20Shader/Specular%20-%20Toon%20Metal/ToonmetalTip.gif)

### Flame

Aka fire

- [ciaccodavide evaporating shader tutorial](https://static.ciaccodavi.de/old/games/shader-test/tutorial/) - See ![Evaporating sharder](Pixel Shader/Flame/Evaporating sharder.mp4)
- [Quick Game Art Tips - Unity Fire Shader | Minions Art on Patreon](https://www.patreon.com/posts/quick-game-art-17021975)
- [How DOOM fire was done](http://fabiensanglard.net/doom_fire_psx/)
- See "The VFX of Diablo" at 28:26 and 30:45

### Sparkle shader

 - ![Sparkle shader](Pixel Shader/Sparkle shader/Sparkle shader.mp4)

- [°.☀️ ｡rob｡☀️.° i love my girlfriend sur Twitter : "got a lot of people asking how i do my sparkly effects and i love the shader tutorials by @minionsart so i got inspired to make my own!! gonna go more in-depth in the replies #gamedev #madewithunity https://t.co/yfKO93yRq7"](https://mobile.twitter.com/bobacupcake/status/957777266959794176)
- [Shader Breakdown #1 | Rob Fichman on Patreon](https://www.patreon.com/posts/shader-breakdown-21471588)

### Filter

- [Fourier Image Filtering](http://david.li/filtering/) - Interactive Fourier transform image filtering. FFT implemented on the GPU via WebGL. See https://github.com/dli/filtering "Any image can be decomposed into the sum of many sinusoids at many different frequencies." gives Gaussian Blur, Sharpen, Edge Detection

### Triplanar Shader

Aka projection, normal mapping

![TriPlanar Shader](Pixel%20Shader/TriPlanar%20shader/TriPlanar%20shader.gif).

- [Normal Mapping for a Triplanar Shader – Ben Golus – Medium](https://medium.com/@bgolus/normal-mapping-for-a-triplanar-shader-10bf39dca05a)
- [Joyce\[MinionsArt\] sur Twitter : "The basics of a UV-Free TriPlanar shader for terrain, with a grassy top layer :) #gamedev #indiedev #tutorial Shader Code Sample in first reply More stuff &gt; https://t.co/FqAsMb9Plg https://t.co/Yb5rpkFuzx"](https://mobile.twitter.com/minionsart/status/958716559609954304)

### Condition optimizations

Instead of

	if (x == 0) {
		y += 5;
	}

Do

	y += 5 * (1.0 - abs(sign(x)));

	vec4 when_eq(vec4 x, vec4 y) {
		return 1.0 - abs(sign(x - y));
	}
	
	vec4 when_neq(vec4 x, vec4 y) {
		return abs(sign(x - y));
	}
	
	vec4 when_gt(vec4 x, vec4 y) {
		return max(sign(x - y), 0.0);
	}
	
	vec4 when_lt(vec4 x, vec4 y) {
		return max(sign(y - x), 0.0);
	}
	
	vec4 when_ge(vec4 x, vec4 y) {
		return 1.0 - when_lt(x, y);
	}
	
	vec4 when_le(vec4 x, vec4 y) {
		return 1.0 - when_gt(x, y);
	}
	
	vec4 and(vec4 a, vec4 b) {
		return a * b;
	}
	
	vec4 or(vec4 a, vec4 b) {
		return min(a + b, 1.0);
	}
	
	vec4 xor(vec4 a, vec4 b) {
		return (a + b) % 2.0;
	}
	
	vec4 not(vec4 a) {
		return 1.0 - a;
	}

- [Avoiding Shader Conditionals](http://theorangeduck.com/page/avoiding-shader-conditionals)

### Lib

From https://github.com/devongovett/glsl.js/blob/master/stdlib.glsl

	// Angle and Trigonometry
	const float PI = 3.141592653589793;
	
	float radians(float degrees) {
		return PI / 180.0 * degrees;
	}
	
	float degrees(float radians) {
		return 180.0 / PI * radians;
	}
	
	float sin(float x);
	float cos(float x);
	float tan(float x);
	float asin(float x);
	float acos(float x);
	float atan(float x);
	
	// sin, cos, tan, asin, acos, atan, atan
	
	// Exponential Functions
	// pow, exp, log, exp2, log2, sqrt, inversesqrt
	float sqrt(float x) {
		return 0.0; // use JS sqrt
	}
	
	// Common Functions
	float abs(float x) {
		return x >= 0.0 ? x : -x;
	}
	
	float sign(float x) {
		return x > 0.0 ? 1.0 : x == 0.0 ? 0.0 : -1.0;
	}
	
	float floor(float x) {
		return float(int(x));
	}
	
	// ceil
	
	float fract(float x) {
		return x - floor(x);
	}
	
	float mod(float x, float y) {
		return x - y * floor(x / y); // TODO: use JS mod directly??
	}
	
	// mod2
	
	float min(float x, float y) {
		return y < x ? y : x;
	}
	
	// min2
	
	float max(float x, float y) {
		return x < y ? y : x;
	}
	
	// max2
	
	float clamp(float x, float min, float max) {
		return min(max(x, min), max);
	}
	
	float mix(float x, float y, float a) {
		return x * (1.0 - a) + y * a;
	}
	
	// mix2
	
	float step(float edge, float x) {
		return x < edge ? 0.0 : 1.0;
	}
	
	// step2
	
	float smoothstep(float edge0, float edge1, float x) {
		float t = clamp((x - edge0) / (edge1 - edge0), 0.0, 1.0);
		return t * t * (3.0 - 2.0 * t);
	}
	
	// Geometric Functions
	float length(vec2 x) {
		return sqrt(x.x * x.x + x.y * x.y);
	}
	
	float distance(vec2 p0, vec2 p1) {
		return length(p0 - p1);
	}
	
	// dopt, cross, normalize, faceforward, reflect, refract
	
	// Matrix functions
	// matrixCompMult, 
	
	// Vector Relational Functions
	bvec2 lessThan(vec2 x, vec2 y) {
		return bvec2(x.x < y.x, x.y < y.y);
	}
	
	bvec2 lessThanEqual(vec2 x, vec2 y) {
		return bvec2(x.x <= y.x, x.y <= y.y);
	}
	
	bvec2 greaterThan(vec2 x, vec2 y) {
		return bvec2(x.x > y.x, x.y > y.y);
	}
	
	bvec2 greaterThanEqual(vec2 x, vec2 y) {
		return bvec2(x.x >= y.x, x.y >= y.y);
	}
	
	bvec2 equal(vec2 x, vec2 y) {
		return bvec2(x.x == y.x, x.y == y.y);
	}
	
	bvec2 notEqual(vec2 x, vec2 y) {
		return bvec2(x.x != y.x, x.y != y.y);
	}
	
	bool any(bvec2 x) {
		return x.x || x.y;
	}
	
	bool all(bvec2 x) {
		return x.x && x.y;
	}
	
	bvec2 not(bvec2 x) {
		return bvec2(!x.x, !x.y);
	}
	
	// Texture Lookup Functions
	// texture2D, texture2DProj, texture2DProgLod, textureCube, textureCubeLod

### Colorblind filter

	// https://github.com/PlanetCentauri/ColorblindFilter
	// https://www.reddit.com/r/gamedev/comments/2i9edg/code_to_create_filters_for_colorblind/
	// MIT
	uniform sampler2D tex;
	uniform int index = 0;
	void main(void) { vec4 c = texture2D(tex, gl_TexCoord[0].st);
	mat3 m[9] = 
	{
		// normal
		mat3(
			1.0    , 0.0    , 0.0  ,
			0.0    , 1.0    , 0.0  ,
			0.0    , 0.0    , 1.0
		),
		// protanopia
		mat3(
			0.56667, 0.43333, 0.0    ,
			0.55833, 0.44167, 0.0    ,
			0.0    , 0.24167, 0.75833
		),
		// protanomaly
		mat3(
			0.81667, 0.18333, 0.0    ,
			0.33333, 0.66667, 0.0    ,
			0.0    , 0.125  , 0.875
		),
		// deuteranopia
		mat3(
			0.625  , 0.375  , 0.0    ,
			0.7    , 0.3    , 0.0    ,
			0.0    , 0.3    , 0.7
		),
		// deuteranomaly
		mat3(
			0.8    , 0.2    , 0.0    ,
			0.25833, 0.74167, 0.0    ,
			0.0    , 0.14167, 0.85833
		),
		// tritanopia
		mat3(
			0.95   , 0.05   , 0.0    ,
			0.0    , 0.43333, 0.56667,
			0.0    , 0.475  , 0.525
		),
		// tritanomaly
		mat3(
			0.96667, 0.03333, 0.0    ,
			0.0    , 0.73333, 0.26667,
			0.0    , 0.18333, 0.81667
		),
		// achromatopsia
		mat3(
			0.299  , 0.587  , 0.114  ,
			0.299  , 0.587  , 0.114  ,
			0.299  , 0.587  , 0.114
		),
		// achromatomaly
		mat3(
			0.618  , 0.320  , 0.062  ,
			0.163  , 0.775  , 0.062  ,
			0.163  , 0.320  , 0.516
		)
	};
	vec3 c2 = {c.r, c.g, c.b};
	c2 *= m[index];
	gl_FragColor = vec4( c2.x , c2.y, c2.z, 1.0 );
	}

- Trichromatic view: Normal
- Anomalous Trichromacy:
	- Red-Weak/Protanomaly
	- Green-Weak/Deuteranomaly
	- Blue-Weak/Tritanomaly
- Dichromatic view:
	- Red-Blind/Protanopia
	- Green-Blind/Deuteranopia
	- Blue-Blind/Tritanopia
- Monochromatic view:
	- Monochromacy/Achromatopsia
	- Blue Cone Monochromacy

- [Color blindness — Wikipedia](https://en.wikipedia.org/wiki/Color_blindness)
- [Color Laboratory -- AWARE Center -- HTML Writers Guild](http://colorlab.wickline.org/colorblind/colorlab/)
- [Colorblind Web Page Filter](http://colorfilter.wickline.org/)
- [Farbwahrnehmungen bei verschiedenen Fehlsichtigkeiten](http://web.archive.org/web/20140705135403/http://sql-und-xml.de/sql-praxis/colour-blindness.html)
- [NoFunc | Color Blindness Library](http://wayback.archive.org/web/20100507232929/http://nofunc.org/Color_Blindness_Library)
- [\<canvas\> + ColorMatrix = Color Blindness](http://web.archive.org/web/20080422231727/http://www.colorjack.com/labs/colormatrix/)
- [Web Student - Building a Colorblindness Simulator - ImageMagick](https://www.imagemagick.org/discourse-server/viewtopic.php?t=17964)
- [Color-Blindness Simulators](http://lpetrich.org/Science/ColorBlindnessSim/ColorBlindnessSim.html)
- [MaPePeR/jsColorblindSimulator: Simulate different kinds of colorblindness on images in your browser.](https://github.com/MaPePeR/jsColorblindSimulator)

![Simple code/result to create filters for colorblind, think about it for your games!](http://s9.postimg.org/fsxy3cdpr/colorblind.png)

### Avoid texture repeation

	// One simple way to avoid texture tile repetition, at the cost of 4 times the amount of texture lookups. Needs GL_NEAREST_MIPMAP_LINEAR for the noise textureto be usable in real life.
	// https://www.shadertoy.com/view/lt2GDd
	// Created by inigo quilez - iq/2015
	// License Creative Commons Attribution-NonCommercial-ShareAlike 3.0 Unported License.
	
	// One simple way to avoid texture tile repetition, at the cost of 4 times the amount of
	// texture lookups (still much better than https://www.shadertoy.com/view/4tsGzf)
	//
	// More info: http://www.iquilezles.org/www/articles/texturerepetition/texturerepetition.htm
	
	#define USEHASH
	
	vec4 hash4( vec2 p ) { return fract(sin(vec4( 1.0+dot(p,vec2(37.0,17.0)), 
												  2.0+dot(p,vec2(11.0,47.0)),
												  3.0+dot(p,vec2(41.0,29.0)),
												  4.0+dot(p,vec2(23.0,31.0))))*103.0); }
	
	vec4 texture2DNoTile( sampler2D samp, in vec2 uv )
	{
		vec2 iuv = floor( uv );
		vec2 fuv = fract( uv );
	
	#ifdef USEHASH	
		// generate per-tile transform (needs GL_NEAREST_MIPMAP_LINEARto work right)
		vec4 ofa = texture2D( iChannel1, (iuv + vec2(0.5,0.5))/256.0 );
		vec4 ofb = texture2D( iChannel1, (iuv + vec2(1.5,0.5))/256.0 );
		vec4 ofc = texture2D( iChannel1, (iuv + vec2(0.5,1.5))/256.0 );
		vec4 ofd = texture2D( iChannel1, (iuv + vec2(1.5,1.5))/256.0 );
	#else
		// generate per-tile transform
		vec4 ofa = hash4( iuv + vec2(0.0,0.0) );
		vec4 ofb = hash4( iuv + vec2(1.0,0.0) );
		vec4 ofc = hash4( iuv + vec2(0.0,1.0) );
		vec4 ofd = hash4( iuv + vec2(1.0,1.0) );
	#endif
		
		vec2 ddx = dFdx( uv );
		vec2 ddy = dFdy( uv );
	
		// transform per-tile uvs
		ofa.zw = sign(ofa.zw-0.5);
		ofb.zw = sign(ofb.zw-0.5);
		ofc.zw = sign(ofc.zw-0.5);
		ofd.zw = sign(ofd.zw-0.5);
		
		// uv's, and derivarives (for correct mipmapping)
		vec2 uva = uv*ofa.zw + ofa.xy; vec2 ddxa = ddx*ofa.zw; vec2 ddya = ddy*ofa.zw;
		vec2 uvb = uv*ofb.zw + ofb.xy; vec2 ddxb = ddx*ofb.zw; vec2 ddyb = ddy*ofb.zw;
		vec2 uvc = uv*ofc.zw + ofc.xy; vec2 ddxc = ddx*ofc.zw; vec2 ddyc = ddy*ofc.zw;
		vec2 uvd = uv*ofd.zw + ofd.xy; vec2 ddxd = ddx*ofd.zw; vec2 ddyd = ddy*ofd.zw;
			
		// fetch and blend
		vec2 b = smoothstep(0.25,0.75,fuv);
		
		return mix( mix( texture2DGradEXT( samp, uva, ddxa, ddya ), 
						 texture2DGradEXT( samp, uvb, ddxb, ddyb ), b.x ), 
					mix( texture2DGradEXT( samp, uvc, ddxc, ddyc ),
						 texture2DGradEXT( samp, uvd, ddxd, ddyd ), b.x), b.y );
	}
	
	void mainImage( out vec4 fragColor, in vec2 fragCoord )
	{
		vec2 uv = fragCoord / iResolution.x;
		
		float f = smoothstep( 0.4, 0.6, sin(iGlobalTime	) );
		float s = smoothstep( 0.4, 0.6, sin(iGlobalTime*0.5) );
			
		uv = (4.0 + 16.0*s)*uv + iGlobalTime*0.1;
			
		vec3 cola = texture2DNoTile( iChannel0, uv ).xyz;
		vec3 colb = texture2D( iChannel0, uv ).xyz;
		
		vec3 col = mix( cola, colb, f );
		
		fragColor = vec4( col, 1.0 );
	}

### Calculate image contrast

Using root mean square (RMS)

http://forum.processing.org/one/topic/calculate-image-contrast-using-root-mean-square-rms.html

	float getContrast() {
		float maxLum = 0;
		float minLum = 10000;
		for (int i=0; i<img.pixels.length; i++) {
		  float r = img.pixels[i] >> 16 & 0xFF;
		  float g = img.pixels[i] >> 8 & 0xFF;
		  float b = img.pixels[i] & 0xFF;
		  float brightness = (0.2126 * r) + (0.7152 * g) + (0.0722 * b);
		  if (brightness > maxLum) maxLum = brightness;
		  if (brightness < minLum) minLum = brightness;
		}
		return (maxLum - minLum)/(maxLum + minLum);
	  }

	  /*
	  https://github.com/jeffThompson/ProcessingTeachingSketches/blob/master/ImageProcessingAndOpenCV/MeasureImageBrightnessAndContrast/MeasureImageBrightnessAndContrast.pde
	  MEASURE IMAGE BRIGHTNESS AND CONTRAST
	  Jeff Thompson | 2013 | www.jeffreythompson.org
	  
	  Measures the overall brightness and contrast in an image.
	  
	  NOTE: this is average for both measures, meaning localized areas of 
	  extreme brightness/contrast may throw off the measurements.
	  
	  Contrast based on this formula:
	  http://en.wikipedia.org/wiki/Contrast_%28vision%29#RMS_contrast
	  
	  Thanks to Amnon Owed for helping figure out the contrast/RMS algorithm!
	  https://forum.processing.org/topic/calculate-image-contrast-using-root-mean-square-rms#25080000001971367
	  */
	  
	  // file to load (gray, mountain, truck)
	  String filename = "truck.jpg";
	  
	  boolean normalizeRange = true;	// normalize results to range of 0-1
	  PImage img;
	  float brightness = 0;
	  float contrast = 0;
	  
	  void setup() {
		  
		img = loadImage(filename);
		size(img.width, img.height);
		image(img, 0,0);
		loadPixels();				   // load pixels into array, iterate!
		
		// find average brightness across image
		for (color c : pixels) {
		  float r = c >> 16 & 0xFF;												 // extract RGB values quickly (better than red(), etc)
		  float g = c >> 8 & 0xFF;
		  float b = c & 0xFF;
		  brightness += (0.2126 * r) + (0.7152 * g) + (0.0722 * b);				 // scales RGB to perceived brightness
		  if (normalizeRange) {
			brightness /= 255.0;													// normalize to 0-1
		  }
		}
		brightness /= pixels.length;												// average result
		println("Average brightness: " + brightness);
		
		// find contrast by comparing average brightness with current value
		for (color c : pixels) {
		  float r = c >> 16 & 0xFF;
		  float g = c >> 8 & 0xFF;
		  float b = c & 0xFF;
		  float pxIntensity = (0.2126 * r) + (0.7152 * g) + (0.0722 * b);
		  if (normalizeRange) {
			   pxIntensity /= 255.0;												// normalizes to range 0-1
		  }
		  contrast += pow((brightness - pxIntensity), 2);
		}
		contrast /= pixels.length;
		println("Average contrast:   " + contrast);
	  }

### Contrast adjustment

	/*
	https://github.com/jeffThompson/ProcessingTeachingSketches/blob/master/ImageProcessingAndOpenCV/ContrastAdjustment/ContrastAdjustment.pde
	CONTRAST ADJUSTMENT
	 Jeff Thompson | 2012 | www.jeffreythompson.org
	 
	 A simple algorithm to adjust image contrast.
	 */
	 
	float increment = 0.5;	// amount to adjust contrast each time the arrow keys are hit
	float contrast = 127;	 // 0 - 255
	PImage source, copy;
	
	void setup() {
	  source = loadImage("cat.jpg");
	  copy = loadImage("cat.jpg");		  // a copy to store the unaltered pixels (ie: non-destructive editing)
	  size(source.width, source.height);
	}
	
	void draw() {
	  image(source, 0, 0);
	}
	
	PImage adjustContrast(PImage img, float contrast) {
		
	  // ensure our contrast is in a legal range of 0-255
	  contrast = constrain(contrast, 0.0, 255.0);
	  
	  // find difference from center (127), equal to the adjustment we make to the image!
	  float adjustment = map(contrast, 0, 255, -127, 127);
	  println(adjustment);
	  
	  img.loadPixels();
	  for (int i=0; i<img.pixels.length; i++) {
		  
		// get RGB values from the pixels and adjust
		float r = img.pixels[i] >> 16 & 0xFF;	// faster equivelant to red() command
		float g = img.pixels[i] >> 8 & 0xFF;	 // ditto green
		float b = img.pixels[i] & 0xFF;		  // and blue! 
		
		// decrease contrast by moving into center (easier)
		if (adjustment < 0) {
		  r = map(r, 0, 255, adjustment, 255-adjustment);
		  g = map(g, 0, 255, adjustment, 255-adjustment);
		  b = map(b, 0, 255, adjustment, 255-adjustment);
		}
		// increase contrast by moving away from center (a bit more complicated
		else {
		  if (r > 127) {
			r = map(r, 0, 255, 127+adjustment, 255);
		  }
		  else {
			r = map(r, 0, 255, 0, 127-adjustment);
		  }
	  
		  if (g > 127) {
			g = map(g, 0, 255, 127+adjustment, 255);
		  }
		  else {
			g = map(g, 0, 255, 0, 127-adjustment);
		  }
	  
		  if (b > 127) {
			b = map(b, 0, 255, 127+adjustment, 255);
		  }
		  else {
			b = map(b, 0, 255, 0, 127-adjustment);
		  }
		}
		
		img.pixels[i] = color(r, g, b);
		// println(r + ", " + g + ", " + b);
	  }
	  img.updatePixels();
	  return img;
	}
	
	void keyPressed() {
	  if (key == CODED) {
		if (keyCode == UP) {
		  contrast += increment;
		  source = adjustContrast(copy, contrast);
		}
		else if (keyCode == DOWN) {
		  contrast -= increment;
		  source = adjustContrast(copy, contrast);
		}
	  }
	  else if (key == 32) {
		setup();
	  }
	}

### Find the darkest points

	/*
	https://github.com/jeffThompson/ProcessingTeachingSketches/blob/master/ImageProcessingAndOpenCV/FindDarkestPointsByNeighborhood/FindDarkestPointsByNeighborhood.pde
	FIND DARKEST POINTS BY NEIGHBORHOOD/DISTANCE
	 Jeff Thompson | 2013 | www.jeffreythompson.org
	 
	 An algorithm to find the darkest points in an image. 
	 
	 While a true centroid algorithm would likely be better, and is possible in Processing
	 (and likely easiest using OpenCV), this is either computationally expensive (ie: slow)
	 and/or requires external libraries and methods.
	 
	 Instead, this is a much lighter-weight example for finding the darkest single-pixel 
	 points within blocks of the image, then compares those results to neighbors, removing
	 ones that are too close to each other.
	 
	 OTHER RESOURCES
	 + Fancier 'clustering algorithms':
	 http://home.dei.polimi.it/matteucc/Clustering/tutorial_html/index.html
	 + A few other ideas (including a Processing sketch that crashed for me) at StackOverflow:
	 https://stackoverflow.com/questions/356035/algorithm-for-detecting-clusters-of-dots
	 + A faster blurring method for Processing, which can be used in conjunction with the
	 above examples:
	 https://forum.processing.org/topic/fast-blurring
	 
	 */
	 
	float storeThresh = 30;		 // points' color must be this dark to be stored (0-255)
	float distThresh = 50;		  // if too close to another point, don't store
	int sampleSize = 20;			// divide image into square of this size (px)
	PImage source, test;			// image objects to load, convert for testing
	
	// resulting pointss (ArrayList for flexibility)
	ArrayList<Integer> darkest = new ArrayList<Integer>();
	
	
	void setup() {
		
	  // load image (here from URL for tidiness) and other setup stuff
	  source = loadImage("http://www.seriouseats.com/recipes/images/20120216-193359-dinner-tonight-steak-taco-salad-primary.jpg");
	  size(source.width, source.height);
	  smooth();
	  noStroke();
	  
	  // copy pixels to another PImage for processing
	  test = createImage(width, height, RGB);
	  test.copy(source, 0, 0, width, height, 0, 0, width, height);
	  test.filter(GRAY);  
	  
	  // go through image block-by-block, finding the darkest pixel and, if it
	  // falls within 'storeThresh', store it to the ArrayList - this helps keep
	  // our computation down, as we don't have to compare EVERY pixel with EVERY OTHER pixel!
	  test.loadPixels();
	  for (int x=0; x < width-sampleSize; x += sampleSize) {				  // go through in blocks
		for (int y=0; y < height-sampleSize; y += sampleSize) {
			
		  // within each sample square, get the darkest pixel
		  // if that pixel is dark enough, add it to the darkest!
		  int darkX = 0;													  // variables for the darkest px's location
		  int darkY = 0;
		  float darkestValue = 255;										   // set a 'world record' of 255 as a starting value
		  for (int sx = x; sx < x+sampleSize; sx++) {						 // iterate through px block
			for (int sy = y; sy < y+sampleSize; sy++) {
			  float currentDark = test.pixels[sy * width + sx] >> 16 & 0xFF;  // red value fine, since we're grayscale only
			  if (currentDark < darkestValue) {							   // if darker than previously stored
				darkestValue = currentDark;								   // store it's value and location
				darkX = sx;
				darkY = sy;
			  }
			}
		  }
		  
		  // if the result is dark enough, store it to the ArrayList! 
		  if (darkestValue <= storeThresh) {
			darkest.add((darkY*width + darkX));	// store location as int in the centroid ArrayList
		  }
		}
	  }
	  println("Found " + darkest.size() + " darkest");
	  
	  // cull the list, looking for pixels that are too close - if they are, delete the current
	  // great solution mostly via: https://stackoverflow.com/a/14389321/1167783
	  println("Culling darkest for proximity...");
	  ArrayList<Integer> results = new ArrayList<Integer>();	// create new ArrayList to store pixels that aren't too close
	all: 
	  for (Integer current : darkest) {						 // label 'all' allows us to continue to outer for loop
		int cx = current % width;							   // get x/y coords of current point
		int cy = current / width;
		for (Integer other : results) {						 // iterate all other points (note this includes the current)
		  int ox = other % width;							   // get x/y of other point
		  int oy = other / width;
		  float d = dist(cx, cy, ox, oy);					   // find distance between the two
		  if (d > 0 && d < distThresh) {						// first tests for the current point, the second if we're far enough away
			continue all;									   // break out and add
		  }
		}
		results.add(current);								   // we made it! add to the results list
	  }
	  darkest = results;										// set to original ArrayList for code-clarity
	  println("Reduced list to " + darkest.size() + " darkest");
	  
	  // display darkest points on top of dimmed image (to more easily see)
	  image(source, 0, 0);
	  fill(255, 100);
	  rect(0, 0, width, height);
	  
	  // draw the darkest points as dots
	  fill(0);
	  for (Integer c : darkest) {
		ellipse(c % width, c/width, 4, 4);
	  }
	}

### World Position Shader

- [Quick Game Art Tips - Unity World Position Shader | Minions Art on Patreon](https://www.patreon.com/posts/quick-game-art-19355776) - See ![World Position Shader](Pixel%20Shader/World%20Position%20Shader/World%20Position%20Shader.gif)

## Optical adjustment

Aka visually centered, physics center, optical alignement, compositional balance

Use center of mass" / centroid, logarithmic weight

Color adjustment (of text where: logo + text) using darker color (adjust brightness) based on the size of the element (number of pixels used)

- [Optical alignement](Design#Optical alignement)
- [Visual Center](http://javier.xyz/visual-center/) - Use the square root of the difference between the pixel and the background color. See https://github.com/javierbyte/visual-center and [visualCenter.js](visualCenter.js)
- [Center of mass — Wikipedia](https://en.wikipedia.org/wiki/Center_of_mass)
- [Centroid — Wikipedia](https://en.wikipedia.org/wiki/Centroid)
- [Triangle Centroid -- from Wolfram MathWorld](http://mathworld.wolfram.com/TriangleCentroid.html)
- [Golden ratio — Wikipedia](https://en.wikipedia.org/wiki/Golden_ratio)
- [G18: Ensuring that a contrast ratio of at least 4.5:1 exists between text (and images of text) and background behind the text | Techniques for WCAG 2.0](https://www.w3.org/TR/2016/NOTE-WCAG20-TECHS-20161007/G18)

## Displacement map

Aka vector field (2D)

- [Vector field — Wikipedia](https://en.wikipedia.org/wiki/Vector_field)
- [Displacement mapping — Wikipedia](https://en.wikipedia.org/wiki/Displacement_mapping)
- [Vector Field with source code – Simon Heys – Freelance iPad / iPhone / iOS app developer in London](https://www.simonheys.com/2007/05/12/vector-field-with-source-code/)

## Fractal

Aka Mandelbrot, Julia

- [Understanding Julia and Mandelbrot Sets](http://www.karlsims.com/julia.html)
- [Inigo Quilez :: fractals, computer graphics, mathematics, demoscene and more](http://www.iquilezles.org/www/index.htm) - "fractals rendering algorithms" and "fractals/complex dynamics"

## Cel shading

- [Cel shading — Wikipedia](https://en.wikipedia.org/wiki/Cel_shading)
- [Humus - 3D](http://www.humus.name/index.php?page=3D&ID=58) - Cel-shading
- [Silhouette Extraction at The Little Grasshopper](http://prideout.net/blog/?p=54)
- [Single Pass Cel Shading – Jean-Marc Le Roux](https://blogs.aerys.in/jeanmarc-leroux/2012/01/23/single-pass-cel-shading/)

## Depth of field

- [Humus - 3D](http://www.humus.name/index.php?page=3D&ID=56) - Depth of field
- [Quasimondo - Mario Klingemann's Flash Blog: Flash 8: Depth Of Field Simulation](http://www.quasimondo.com/archives/000564.php) - Apply Depth Of Field to 2D image

## Particles

Aka fluid, smoke, flame, volume rendering

Can be combined with volume and transparent textures

See also [cloud](#Cloud), [water](#Water), [flame](#Flame), [distortion](#Distortion), [impostor](#Impostor)

- See "The VFX of Diablo" at 31:37
- [Humus - 3D](http://www.humus.name/index.php?page=3D&ID=13) - Particle system
- [100,000 Particle Shader by Charlie Hoey](http://charliehoey.com/threejs-demos/shader_demo5.html)
- [WebGL GPU Particles - BETA!](http://www.iamnop.com/particles-mrt/) - https://github.com/nopjia/webgl-particles
- [A Particle Dream](https://github.com/nopjia/webgl-particles2) - [bits and pixels: WebGL GPU Particles](http://nopjia.blogspot.fr/2014/06/webgl-gpu-particles.html)
- [The Spirit - WebGL Experiment](https://github.com/edankwan/The-Spirit)
- [VolumetricFire](https://github.com/yomotsu/VolumetricFire) - a JS lib ported from Alfred Fuller's Real-time Procedural Volumetric Fire Demo
- [Sketches](http://yiwenl.github.io/Sketches/) - A collection of Yi-wen LIN's WebGL sketches. https://github.com/yiwenl/Sketches
- [The New Particle « simppa.fi/blog](http://www.simppa.fi/blog/the-new-particle/) - tips
- [The Polygon Shredder](https://www.clicktorelease.com/code/polygon-shredder/) - see https://github.com/spite/polygon-shredder
- [Hyper Mix](https://github.com/edankwan/hyper-mix) - see [Hyper Mix](http://edankwan.com/experiments/hyper-mix/)
- "`THREE.Points` compatible fire particle" — Akihiro Oyamada - See [=^.^=](https://yomotsu.neocities.org/2/) and https://yomotsu.neocities.org/2/ParticleFire.js
- [A stupendous amount of confetti](https://codepen.io/zadvorsky/pen/rVaZoP)
- [Volumetric Particle Flow](http://david.li/flow/) - see [Volumetric Particle Flow](https://github.com/dli/flow)
- [Vortex Spheres](http://david.li/vortexspheres/) - see [Vortex Spheres](https://github.com/dli/vortexspheres)
- [Wireframe Tendrils ThreeJS Shader by Charlie Hoey](http://charliehoey.com/threejs-demos/wireframe-tendrils-shader.html) - Map the RGB values of a seamless color Perlin Noise texture to the xyz positions of the vertices in a plane. I then render it wireframe and apply the color of the original texture to each vertex, and slowly pan the original texture across to make each vertex essentially flow along the lines of the texture. There are over 250,000 vertices in this simulation
- [@cabbibo](http://cabbi.bo/Text/) - Text particles. See https://github.com/cabbibo/Text
- [Your Majesty Logo Helmet](http://codepen.io/toreholmberg/pen/pbxNwr) - Decomposition / recomposition of a 3D model
- [sketch of three.js](http://ykob.github.io/sketch-threejs/) - Sketch-threejs by Yoichi Kobayashi. See https://github.com/ykob/sketch-threejs/
- [GPGPU Geometry :: webVR Prototype](http://sirokos.com/GPUAsteroids/)
- InstanceMesh [http://cabbi.bo/InstanceMesh/Curl/](http://cabbi.bo/InstanceMesh/Curl/) and http://cabbi.bo/InstanceMesh/
- [Particle Helix - Multiple](http://codepen.io/gskinner/pen/mmbpjv)
- [Beautifully Animate Points with WebGL and regl - Peter Beshai](http://peterbeshai.com/beautifully-animate-points-with-webgl-and-regl.html) - Data viz and transitions
- [Canvas Filters](https://codepen.io/osublake/pen/RLOzxo)
- [chromeography - Codevember 2017](https://www.clicktorelease.com/code/codevember-2017/chromeography/)
- [3D Particle Explorations | Codrops](https://tympanus.net/codrops/2017/12/12/3d-particle-explorations/)
- [Electricity](http://sketches.vlucendo.com/electricity/)
- [Interactive Particles with Three.js | Codrops](https://tympanus.net/codrops/2019/01/17/interactive-particles-with-three-js/)

- [Fluid - Experiments - Yuichiroh Arai](https://www.yuichiroharai.com/experiments/fluid/)
- [Fluid Particles](http://david.li/fluid/) - https://github.com/dli/fluid
- [Interactive Fluid Simulation for Video Games - Dr. Michael J. Gourlay](http://www.mijagourlay.com/fluid)
- https://code.google.com/archive/p/smoke3d/ - A very small 3D smoke animation solver that uses the semi-Lagrangian advection and the multigrid pressure solver
- [MIDI Smoke Simulator](https://github.com/dli/midismoke)

Volume rendering

- [An eye into my World -Tricks, Thoughts, Ideas, Solutions: GPU Volume Rendering](http://mmmovania.blogspot.fr/search/label/GPU%20Volume%20Rendering)
- [Single-Pass Raycasting at The Little Grasshopper](http://prideout.net/blog/?p=64)
- [Production Volume Rendering](https://github.com/pvrbook/pvr) - This is the companion rendering library for the book Production Volume Rendering
- [GPU volume rendering test on Vimeo](https://vimeo.com/16159247) - see [Miles Macklin » Blog Archive » Adventures in Fluid Simulation](http://blog.mmacklin.com/2010/11/01/adventures-in-fluid-simulation/)

## Frustum culling

- [Inigo Quilez :: fractals, computer graphics, mathematics, demoscene and more](http://www.iquilezles.org/www/articles/frustumcorrect/frustumcorrect.htm) - correct frustum culling
- [Inigo Quilez :: fractals, computer graphics, mathematics, demoscene and more](http://www.iquilezles.org/www/articles/frustum/frustum.htm) - minimal frustum culling

## Enhance detail

Aka Film grain, details restoration

See [noise and dithering](Random, noise and dithering)

	// "video" is your video object istance
	var filter:ConvolutionFilter = new flash.filters.ConvolutionFilter();
	filter.matrixX = 3;
	filter.matrixY = 3;
	filter.matrix = [-1, 0, -1, 0, 8, 0, -1, 0, -1];
	filter.bias =  0;
	filter.divisor = 4;
	video.filters = [filter];

	// Init noise frames
	var baseX:Number = 1.3;
	var baseY:Number = 1.3;
	var numOctaves:Number = 1;
	var stitch:Boolean = true;
	var fractalNoise:Boolean = true;
	var channelOptions:Number = BitmapDataChannel.BLUE | BitmapDataChannel.RED | BitmapDataChannel.GREEN;
	var grayScale:Boolean = false;
	var offsets:Array = new Array(new Point(), new Point());
	var bitmapArray:Array = new Array();
	var frameNumber:Number = 12;
	
	for (var i = 0; i < frameNumber; i++)
	{
		var bmpData:BitmapData = new BitmapData(1280, 720);
		var bmp:Bitmap = new Bitmap(bmpData);
		bmp.alpha = 0.20;
		bmp.blendMode = "overlay";
		bmpData.perlinNoise(baseX, baseY, numOctaves, Math.random() * 65000, stitch, fractalNoise, channelOptions, grayScale, offsets);
		bmp.visible = false;
		bitmapArray.push(bmp);
	}

	// Noise video sequence
	var altcnt:uint = 0;
	
	addEventListener(Event.ENTER_FRAME, frameHandler);
	function frameHandler(event:Event):void
	{
		altcnt = altcnt >= frameNumber ? 0 : altcnt + 1;
		for(var i = 0; i < frameNumber; i++)
			bitmapArray[i].visible = false;
		bitmapArray[altcnt].visible = true;
		bitmapArray[altcnt].alpha = (0.14 + 0.06 * Math.random()) * 1.5;
	}

- [How To Optimize Images With HTML5 Canvas – Smashing Magazine](https://www.smashingmagazine.com/2011/08/optimize-images-with-html5-canvas/#generating-noise) - Noise can be used to increase details
- [Flash + H.264 = H.264 Squared – Part III | Video Encoding & Streaming Technologies](https://sonnati.wordpress.com/2010/10/06/flash-h-264-h-264-squared-%E2%80%93-part-iii/)
- [Flash + H.264 = H.264 Squared – Part II | Video Encoding & Streaming Technologies](https://sonnati.wordpress.com/2010/10/01/flash-h-264-h-264-squared-part-ii/)

## VR

See [projection](Projection)

- [Inigo Quilez :: fractals, computer graphics, mathematics, demoscene and more](http://www.iquilezles.org/www/articles/stereo/stereo.htm) - Stereo rendering
- [Inigo Quilez :: fractals, computer graphics, mathematics, demoscene and more](http://www.iquilezles.org/www/articles/basicvr/basicvr.htm) - How to render in VR
- [Speeding up GPU barrel distortion correction in mobile VR - Imagination Technologies](https://www.imgtec.com/blog/speeding-up-gpu-barrel-distortion-correction-in-mobile-vr/)

## Blend mode

- [SVG Compositing Specification](https://www.w3.org/TR/SVGCompositing/)
- [Layer Blending Modes in Photoshop - Dreamstale](http://www.dreamstale.com/layer-blending-modes-in-photoshop/)
- [Blend Modes](http://www.nutty.ca/articles/blend_modes/) - using WebGL
- [Blend Modes for OpenGL](http://fr.slideshare.net/Mark_Kilgard/blend-modes-for-opengl)
- [Can image transparency be calculated automatically from multiple non-transparent samples? - Graphic Design Stack Exchange](http://graphicdesign.stackexchange.com/questions/31337/can-image-transparency-be-calculated-automatically-from-multiple-non-transparent)

Compute blend mode: (image A and image B): [Photoshop math with GLSL shaders](http://wayback.archive.org/web/20100508034307/http://blog.mouaif.org/2009/01/05/photoshop-math-with-glsl-shaders/) - see also the file `PhotoshopMathFP.hlsl`

**Note: Other algorithms below are kept here for reference only**

> 	multiply 	a * b
> 	screen 	1 - (1 - a) * (1 - b)
> 	darken 	min(a, b)
> 	lighten 	max(a, b)
> 	difference 	abs(a - b)
> 	negation 	1 - abs(1 - a - b)
> 	exclusion 	a + b - 2 * a * b
> 	overlay 	a < .5 ? (2 * a * b) : (1 - 2 * (1 - a) * (1 - b))
> 	hard light 	b < .5 ? (2 * a * b) : (1 - 2 * (1 - a) * (1 - b))
> 	soft light 	b < .5 ? (2 * a * b + a * a * (1 - 2 * b)) : (sqrt(a) * (2 * b - 1) + (2 * a) * (1 - b))
> 	dodge 	a / (1 - b)
> 	burn 	1 - (1 - a) / b
— [Pegtop delphi](http://www.pegtop.net/delphi/articles/blendmodes/)

> 	// multiply
> 	// c' = Math.floor( ( c1 * c0 ) / 0xff )
> 	// screen
> 	// c' = 255 - Math.floor( ( 255 - c0 ) * ( 255 - c1 ) / 255 )
> 	// darken
> 	// c' = c0 < c1 ? c0 : c1
> 	// lighten
> 	// c' = c0 > c1 ? c0 : c1
> 	// difference
> 	// c' = c0 > c1 ? c0 - c1 : c1 - c0
> 	// overlay
> 	// c' = c0 < 128 ? Math.floor( ( c1 * c0 ) / 127 ) : 255 - Math.ceil( ( 255 - c0 ) * ( 255 - c1 ) / 127 )
> 	// hard light
> 	// c' = c1 < 128 ? Math.floor( ( c1 * c0 ) / 127 ) : 255 - Math.ceil( ( 255 - c0 ) * ( 255 - c1 ) / 127 )
> 	// add
> 	// c' = Math.min( 255, Math.max( 0, c0 + c1 ) )
> 	// subtract
> 	// c' = Math.max( 0, c0 - c1 )
> 	// invert ( no influence from c1 )
> 	// c' = 255 - c0
— [Andre Michelle » Blog Archive » BlendMode Math](http://wayback.archive.org/web/20140213144344/http://blog.andre-michelle.com/2005/blendmodes-math/)

> 	#define ChannelBlend_Normal(A,B)	 ((uint8)(A))
> 	#define ChannelBlend_Lighten(A,B)	((uint8)((B > A) ? B:A))
> 	#define ChannelBlend_Darken(A,B)	 ((uint8)((B > A) ? A:B))
> 	#define ChannelBlend_Multiply(A,B)   ((uint8)((A * B) / 255))
> 	#define ChannelBlend_Average(A,B)	((uint8)((A + B) / 2))
> 	#define ChannelBlend_Add(A,B)		((uint8)(min(255, (A + B))))
> 	#define ChannelBlend_Subtract(A,B)   ((uint8)((A + B < 255) ? 0:(A + B - 255)))
> 	#define ChannelBlend_Difference(A,B) ((uint8)(abs(A - B)))
> 	#define ChannelBlend_Negation(A,B)   ((uint8)(255 - abs(255 - A - B)))
> 	#define ChannelBlend_Screen(A,B)	 ((uint8)(255 - (((255 - A) * (255 - B)) >> 8)))
> 	#define ChannelBlend_Exclusion(A,B)  ((uint8)(A + B - 2 * A * B / 255))
> 	#define ChannelBlend_Overlay(A,B)	((uint8)((B < 128) ? (2 * A * B / 255):(255 - 2 * (255 - A) * (255 - B) / 255)))
> 	#define ChannelBlend_SoftLight(A,B)  ((uint8)((B < 128)?(2*((A>>1)+64))*((float)B/255):(255-(2*(255-((A>>1)+64))*(float)(255-B)/255))))
> 	#define ChannelBlend_HardLight(A,B)  (ChannelBlend_Overlay(B,A))
> 	#define ChannelBlend_ColorDodge(A,B) ((uint8)((B == 255) ? B:min(255, ((A << 8 ) / (255 - B)))))
> 	#define ChannelBlend_ColorBurn(A,B)  ((uint8)((B == 0) ? B:max(0, (255 - ((255 - A) << 8 ) / B))))
> 	#define ChannelBlend_LinearDodge(A,B)(ChannelBlend_Add(A,B))
> 	#define ChannelBlend_LinearBurn(A,B) (ChannelBlend_Subtract(A,B))
> 	#define ChannelBlend_LinearLight(A,B)((uint8)(B < 128)?ChannelBlend_LinearBurn(A,(2 * B)):ChannelBlend_LinearDodge(A,(2 * (B - 128))))
> 	#define ChannelBlend_VividLight(A,B) ((uint8)(B < 128)?ChannelBlend_ColorBurn(A,(2 * B)):ChannelBlend_ColorDodge(A,(2 * (B - 128))))
> 	#define ChannelBlend_PinLight(A,B)   ((uint8)(B < 128)?ChannelBlend_Darken(A,(2 * B)):ChannelBlend_Lighten(A,(2 * (B - 128))))
> 	#define ChannelBlend_HardMix(A,B)	((uint8)((ChannelBlend_VividLight(A,B) < 128) ? 0:255))
> 	#define ChannelBlend_Reflect(A,B)	((uint8)((B == 255) ? B:min(255, (A * A / (255 - B)))))
> 	#define ChannelBlend_Glow(A,B)	   (ChannelBlend_Reflect(B,A))
> 	#define ChannelBlend_Phoenix(A,B)	((uint8)(min(A,B) - max(A,B) + 255))
> 	#define ChannelBlend_Alpha(A,B,O)	((uint8)(O * A + (1 - O) * B))
> 	#define ChannelBlend_AlphaF(A,B,F,O) (ChannelBlend_Alpha(F(A,B),A,O))
— [c++ - How does photoshop blend two images together? - Stack Overflow](https://stackoverflow.com/questions/5919663/how-does-photoshop-blend-two-images-together/5925219#5925219)

- [Photoshop Blend Mode Math](http://wayback.archive.org/web/20080123092608/http://www.nathanm.com/photoshop-blending-math/)

### Blend normal maps

- [Shader Sandbox](http://blog.selfshadow.com/sandbox/normals.html) - see [Blending in Detail - Self Shadow](http://blog.selfshadow.com/publications/blending-in-detail/)

### Premultiplied alpha

Premultiplied (matted) vs straight alpha (unmatted)

> The reason to do this is performance. The image processing algorithm to **composite two bitmaps always requires that the alpha channels are being multplied into the color information**, so if you have a tool that needs to do a lot of compositing it simply saves you a good amount of time if you don't have to do these multiplications for every pixel.

`gl.pixelStorei(gl.UNPACK_PREMULTIPLY_ALPHA, true);` to pre multiply alpha of pixels of textures (call it before uploading pixel data with `texImage2D()` and `texSubImage2D()` only)
`gl.pixelStorei(gl.UNPACK_UNMULTIPLY_ALPHA, true);` to unmultiply alpha of pixels of textures (call it before uploading pixel data with `texImage2D()` and `texSubImage2D()` only)
`gl.blendFunc(gl.SRC_ALPHA, gl.ONE_MINUS_SRC_ALPHA);` blend mode when draw with a compressed texture without pre-multiplied alpha
`gl.blendFunc(gl.ONE, gl.ONE_MINUS_SRC_ALPHA);` blend mode when draw with a compressed texture with pre-multiplied alpha
`gl.blendFuncSeparate(gl.SRC_ALPHA, gl.ONE_MINUS_SRC_ALPHA, gl.ONE, gl.ONE_MINUS_SRC_ALPHA);`

Non premultiplied operation:

	// blend(source, dest)
	result = (source.rgb * source.a) + (dest.rgb * (1 – source.a))

Premultiplied operation:

	rgba(0, 1, 0, 0.5) -> rgba(0, 0.5, 0, 0.5)//color.rgb *= color.a

	// blend(source, dest)
	result = source.rgb + (dest.rgb * (1 – source.a))

See premultiplied alpha data loss due to rounding

	// From http://www.quasimondo.com/premultipliedAlpha/
	[Embed(source="assets/example.jpg")]
	private static const PICTURE: Class;
	
	private var original:BitmapData;
	private var alphaMap:BitmapData;
	private var displayMap:BitmapData;
	private const origin:Point = new Point();
	private const rect:Rectangle = new Rectangle();
	private const ct:ColorTransform = new ColorTransform();
	
	private function init():void
	{
		var sourceHolder:Bitmap = Bitmap( new PICTURE() );
	
		original = new BitmapData( sourceHolder.width, sourceHolder.height, true, 0 );
		original.draw( sourceHolder );
	
		rect.width = original.width;
		rect.height = original.height;
	
		alphaMap   = new BitmapData( original.width, original.height, true, 0x00000000 );
		displayMap = new BitmapData( original.width, original.height, true, 0xff000000 );
	
		display.source = new Bitmap( displayMap );
	
		update();
	}
	
	private function update():void
	{
		displayMap.copyPixels( original, original.rect, origin );
		alphaMap.fillRect( alphaMap.rect, alphaValue.value << 24 );
	
		displayMap.copyChannel( alphaMap, displayMap.rect, origin, 8, 8 );
		displayMap.copyChannel( original, displayMap.rect, origin, 8, 8 );
	
		if ( dataLoss.selected )
		{
			displayMap.draw( original, null, null, "difference" );
			ct.redMultiplier = ct.greenMultiplier = ct.blueMultiplier = 0.25 * ( 256 - Math.sqrt(alphaValue.value));
			displayMap.colorTransform( displayMap.rect, ct );
	
		}
	
		rect.width = ( splitImage.value / 100) * original.width;
		displayMap.copyPixels( original, rect, origin );
	}

	var map:BitmapData = new BitmapData(1,1,true,0xffffffff);
	map.setPixel32(0,0,0x00ffffff); // RGBA(255, 255, 255, 0);`
	trace( map.getPixel32(0,0).toString(16)) // traces 0x00000000
	map.setPixel32(0,0,0x20fcfcfc);
	trace( map.getPixel32(0,0).toString(16)) // traces 0x20ffffff

- [Quasimondo - Mario Klingemann's Flash Blog: The Dirty Secrets of Premultiplied Alpha](http://www.quasimondo.com/archives/000665.php)
- [Premultiplied alpha – Shawn Hargreaves Blog](https://blogs.msdn.microsoft.com/shawnhar/2009/11/06/premultiplied-alpha/)
- [Premultiplied alpha and image composition – Shawn Hargreaves Blog](https://blogs.msdn.microsoft.com/shawnhar/2009/11/07/premultiplied-alpha-and-image-composition/)
- [Real-Time Rendering · GPUs prefer premultiplication](http://www.realtimerendering.com/blog/gpus-prefer-premultiplication/)
- [WebGL, Blending, and Why You're Probably Doing it Wrong](https://limnu.com/webgl-blending-youre-probably-wrong/)
- [A Mind Forever Programming: Why Alpha Premultiplied Colour Blending Rocks](http://amindforeverprogramming.blogspot.fr/2013/07/why-alpha-premultiplied-colour-blending.html)
- [Understanding premultiplied alpha - eppz!](http://eppz.eu/blog/understanding-premultiplied-alpha/)
- [Wrangle Premultiplied Alpha - iPhone 3D Programming](http://chimera.labs.oreilly.com/books/1234000001814/ch06.html#ch06_id36000761)
- [Distant Souls Development Blog: Premultiplied Alpha: Online Interactive demo](http://distantsoulsdev.blogspot.fr/2013/02/premultiplied-alpha-online-interactive.html)
- [Alpha Blending for Leaves](http://www.td-grafik.de/ext/xfrog/alpha/)
- [Messy Alpha Problem - White around edges - Unity Answers](http://answers.unity3d.com/questions/10302/messy-alpha-problem-white-around-edges.html)
- [Unreal Cascade: Making Proper Alpha Channels for VFX - YouTube](https://www.youtube.com/watch?v=oh2WGL8hvPo)
- Fragment shader with non-premultiplied alpha [opengl - Fragment shader and coloring a texture - Stack Overflow](https://stackoverflow.com/questions/18783752/fragment-shader-and-coloring-a-texture)

## Line

Aka trail, wireframe

See [Line anti-aliasing](#Line anti-aliasing)

- [WebGL rendering of solid trails - Codeflow](http://codeflow.org/entries/2012/aug/05/webgl-rendering-of-solid-trails/)
- [Drawing Lines is Hard](https://mattdesl.svbtle.com/drawing-lines-is-hard) - See https://github.com/mattdesl/webgl-lines
- [Minko 2.0 New Feature: Wireframe Rendering – Jean-Marc Le Roux](https://blogs.aerys.in/jeanmarc-leroux/2011/12/17/minko-2-0-new-feature-wireframe-rendering/) - https://github.com/thepalebluedot/minimole-core/blob/master/com/li/minimole/materials/pb3d/PB3DWireframeMaterialSimple.as
- [Shader-Based Wireframe Drawing](http://wayback.archive.org/web/20140213062544/http://cgg-journal.com/2008-2/06/index.html)

## Resize

See [Resample](Resample), Vector, LOD and midmapping

Grid (9 slice scaling):

- [ScaleBitmap : New version \< ByteArray.org](http://www.bytearray.org/?p=1206) - see https://gist.github.com/didierbrun/264250

### Seam carving

- [Seam carving](https://en.wikipedia.org/wiki/Seam_carving)
- [Quasimondo - Mario Klingemann's Flash Blog: Optimizing Seam Carving](http://www.quasimondo.com/archives/000652.php)
- [*drawlogic » AS3 Content Aware Resizing or Image Seam Carving - web, mobile, game + interactive development » AS3 Content Aware Resizing or Image Seam Carving » AS3 Content Aware Resizing or Image Seam Carving](http://drawlogic.com/2007/09/04/as3-content-aware-resizing-or-image-seam-carving/)
- https://github.com/jeffThompson/ProcessingTeachingSketches/tree/master/ImageProcessingAndOpenCV/SeamCarving
- http://www.libspark.org/svn/as3/SeamCarving/src/org/libspark/display/SeamCarving.as

## Optical illusion

- [Optical illusion — Wikipedia](https://en.wikipedia.org/wiki/Optical_illusion)
- [Catalogue of illusions](http://www.psy.ritsumei.ac.jp/~akitaoka/cataloge.html)
- [Akiyoshi's illusion pages](http://www.psy.ritsumei.ac.jp/~akitaoka/index-e.html)
